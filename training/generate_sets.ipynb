{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as td\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_open = \"../concat_data_tagged/\"\n",
    "enable_kfold = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Takes images in concat_data and flatten them into a 1D array\n",
    "def flatten_images():\n",
    "    images_dict = {'focused': [],\n",
    "                    'happy': [],\n",
    "                    'neutral': [],\n",
    "                    'surprised': []}\n",
    "    image_name_dict = {'focused': [],\n",
    "                    'happy': [],\n",
    "                    'neutral': [],\n",
    "                    'surprised': []}\n",
    "    \n",
    "    for category in ['focused', 'happy', 'neutral', 'surprised']:\n",
    "        #Get the list of images in the directory\n",
    "        images = os.listdir(path_to_open + \"%s\" % category)\n",
    "        #Create an empty list to store the flattened images\n",
    "        flattened_images = []\n",
    "        #Iterate through the images\n",
    "        \n",
    "        for image in images:\n",
    "            #check extension of the image\n",
    "            if image.split(\".\")[-1] == \"jpg\":\n",
    "                #Read the image\n",
    "                img = cv2.imread(path_to_open + \"%s/%s\" %(category, image), 0)\n",
    "                #Flatten the image\n",
    "                # img = img.flatten()\n",
    "                #Add the flattened image to the list\n",
    "                images_dict[category].append(img)\n",
    "                # image_name_dict[category].append(category + \"_\" + image)\n",
    "                image_name_dict[category].append(image)\n",
    "\n",
    "\n",
    "    #Return the list of flattened images\n",
    "    return images_dict, image_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_image(image_path):\n",
    "    img = cv2.imread(image_path, 0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation functions\n",
    "\n",
    "def flip(image):\n",
    "    return cv2.flip(image, 1) # flipping around y-axis\n",
    "\n",
    "def rotate(image):\n",
    "    angle = np.random.uniform(-5,5)\n",
    "    M = cv2.getRotationMatrix2D((image.shape[1] / 2, image.shape[0] / 2), angle, 1)\n",
    "    return cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "def brighten(image):\n",
    "    grey = False\n",
    "    if len(image.shape) == 2:\n",
    "        grey = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    factor = np.random.uniform(0.5, 1.5)\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hsv[:,:,2] = np.clip(hsv[:,:,2] * factor, 0, 255)\n",
    "    bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR) \n",
    "    return bgr if not grey else cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "def change_contrast(image):\n",
    "    factor = np.random.uniform(0.5, 1.5)\n",
    "    return cv2.convertScaleAbs(image, alpha=factor, beta=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(images, labels):\n",
    "    augmented_images = []\n",
    "    augmented_labels = []\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        image = images[i]\n",
    "        label = labels[i]\n",
    "\n",
    "        # save original image\n",
    "        augmented_images.append(image)\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "        # flipping\n",
    "        augmented_images.append(flip(image))\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "        # rotating\n",
    "        augmented_images.append(rotate(image))\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "        # brightening\n",
    "        augmented_images.append(brighten(image))\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "        # changing contrast\n",
    "        augmented_images.append(change_contrast(image))\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "    return augmented_images, augmented_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['107_face-expression-recognition-dataset-jonathan-oheix_female_black_adult.jpg', '392_chicago-faces_female_adult_black.jpg', '192_chicago-faces_female_adult_black.jpg', '182_chicago-faces_male_adult_white.jpg', '66_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '364_chicago-faces_male_adult_asian.jpg', '178_chicago-faces_male_adult_asian.jpg', '204_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '486_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '280_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_young.jpg', '11_focused-face-FER-2013-luis-MANAS-SAMBARE_female_asian_adult.jpg', '330_face-expression-recognition-dataset-jonathan-oheix_female_black_adult.jpg', '35_MMA-FACIAL-EXPRESSION-mahmoud_female_white_adult.jpg', '162_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '217_chicago-faces_female_adult_black.jpg', '11_UTK-sanjaya_female_white_adult.jpg', '65_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '48_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '88_chicago-faces_male_adult_asian.jpg', '472_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '200_chicago-faces_female_adult_black.jpg', '120_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_old.jpg', '175_angry-face-expression-recognition-dataset-jonathan-oheix_male_black_young.jpg', '184_angry-face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '378_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_young.jpg', '240_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '185_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_old.jpg', '57_UTK-sanjaya_female_black_adult.jpg', '182_face-expression-recognition-dataset-jonathan-oheix_female_white_young.jpg', '78_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '106_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '259_chicago-faces_female_adult_asian.jpg', '31_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '483_chicago-faces_male_adult_hispanic.jpg', '141_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '420_chicago-faces_male_adult_white.jpg', '144_chicago-faces_female_adult_white.jpg', '135_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_young.jpg', '215_chicago-faces_female_adult_white.jpg', '402_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_adult.jpg', '118_MMA-FACIAL-EXPRESSION-mahmoud_male_asian_adult.jpg', '132_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '50_chicago-faces_male_adult_black.jpg', '15_MMA-FACIAL-EXPRESSION-mahmoud_male_black_adult.jpg', '77_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '129_MMA-FACIAL-EXPRESSION-mahmoud_male_black_adult.jpg', '161_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '49_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '270_chicago-faces_male_adult_white.jpg', '127_kaggle__zawarkhan69__human-facial-expression-dataset_female_old_white.jpg', '101_chicago-faces_male_adult_white.jpg', '368_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '323_chicago-faces_male_adult_white.jpg', '59_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', '150_chicago-faces_male_adult_black.jpg', '270_chicago-faces_male_adult_black.jpg', '14_human-facial-expression-dataset_male_white_adult.jpg', '278_chicago-faces_male_adult_black.jpg', '11_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_adult.jpg', '70_chicago-faces_male_adult_white.jpg', '148_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', '442_face-expression-recognition-dataset-jonathan-oheix_male_white_young.jpg', '50_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', '117_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', '26_angry-face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '227_chicago-faces_male_adult_black.jpg', '168_MMA-FACIAL-EXPRESSION-mahmoud_female_black_adult.jpg', '460_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_young.jpg', '140_chicago-faces_female_adult_white.jpg', '415_face-expression-recognition-dataset-jonathan-oheix_male_white_old.jpg', '118_chicago-faces_female_adult_black.jpg', '309_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_adult.jpg', '55_angry-face-expression-recognition-dataset-jonathan-oheix_male_other_race_adult.jpg', '105_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '222_chicago-faces_male_adult_white.jpg', '355_chicago-faces_female_adult_asian.jpg', '382_face-expression-recognition-dataset-jonathan-oheix_female_white_old.jpg', '301_chicago-faces_female_adult_white.jpg', '238_face-expression-recognition-dataset-jonathan-oheix_female_asian_young.jpg', '409_chicago-faces_male_adult_asian.jpg', '57_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '5_UTK-sanjaya_female_black_adult.jpg', '107_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '106_chicago-faces_male_adult_black.jpg', '188_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '170_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '71_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '426_chicago-faces_male_adult_asian.jpg', '67_angry-face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '421_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '174_chicago-faces_female_adult_asian.jpg', '256_chicago-faces_female_adult_black.jpg', '93_chicago-faces_male_adult_white.jpg', '367_chicago-faces_male_adult_white.jpg', '212_angry-face-expression-recognition-dataset-jonathan-oheix_male_black_adult.jpg', '191_chicago-faces_male_adult_black.jpg', '121_chicago-faces_male_adult_asian.jpg', '5_MMA-FACIAL-EXPRESSION-mahmoud_female_white_adult.jpg', '3_UTK-sanjaya_male_white_adult.jpg', '485_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '192_face-expression-recognition-dataset-jonathan-oheix_male_asian_adult.jpg', '266_chicago-faces_female_adult_black.jpg', '246_chicago-faces_male_adult_black.jpg', '132_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', '96_chicago-faces_male_adult_white.jpg', '375_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '168_chicago-faces_female_adult_white.jpg', '82_chicago-faces_male_adult_white.jpg', '234_chicago-faces_female_adult_white.jpg', '316_chicago-faces_male_adult_asian.jpg', '192_chicago-faces_female_adult_white.jpg', '467_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_young.jpg', '365_chicago-faces_male_adult_hispanic.jpg', '371_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '175_chicago-faces_male_adult_asian.jpg', '125_kaggle__zawarkhan69__human-facial-expression-dataset_female_adult_white.jpg', '201_chicago-faces_male_adult_asian.jpg', '445_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_young.jpg', '490_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '135_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '37_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', '5_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '69_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '340_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '40_chicago-faces_male_adult_hispanic.jpg', '351_chicago-faces_male_adult_asian.jpg', '16_chicago-faces_female_adult_black.jpg', '25_face-expression-recognition-dataset-jonathan-oheix_male_white_young.jpg', '453_chicago-faces_female_adult_asian.jpg', '94_chicago-faces_female_adult_asian.jpg', '416_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '20_chicago-faces_male_adult_white.jpg', '150_face-expression-recognition-dataset-jonathan-oheix_female_white_young.jpg', '150_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '62_MMA-FACIAL-EXPRESSION-mahmoud_female_asian_adult.jpg', '480_face-expression-recognition-dataset-jonathan-oheix_male_white_young.jpg', '353_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '155_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '44_face-expression-recognition-dataset-jonathan-oheix_female_white_young.jpg', '17_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '388_chicago-faces_male_adult_asian.jpg', '184_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', '70_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '434_chicago-faces_male_adult_asian.jpg', '154_chicago-faces_female_adult_hispanic.jpg', '451_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_young.jpg', '72_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '253_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '53_chicago-faces_male_adult_white.jpg', '245_face-expression-recognition-dataset-jonathan-oheix_male_white_young.jpg', '145_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_young.jpg', '12_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_young.jpg', '47_MMA-FACIAL-EXPRESSION-mahmoud_female_asian_adult.jpg', '297_chicago-faces_male_adult_white.jpg', '245_chicago-faces_female_adult_black.jpg', '75_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '28_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '26_chicago-faces_male_adult_black.jpg', '43_chicago-faces_male_adult_hispanic.jpg', '256_chicago-faces_male_adult_white.jpg', '488_chicago-faces_male_adult_white.jpg', '261_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_young.jpg', '466_chicago-faces_female_adult_white.jpg', '221_chicago-faces_female_adult_asian.jpg', '4_angry-face-expression-recognition-dataset-jonathan-oheix_male_black_adult.jpg', '462_chicago-faces_female_adult_black.jpg', '41_chicago-faces_female_adult_hispanic.jpg', '119_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_young.jpg', '96_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_young.jpg', '20_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '10_UTK-sanjaya_male_black_adult.jpg', '333_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '163_chicago-faces_female_adult_asian.jpg', '73_chicago-faces_male_adult_black.jpg', '425_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_young.jpg', '154_angry-face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '108_chicago-faces_female_adult_white.jpg', '294_chicago-faces_female_adult_black.jpg', '168_face-expression-recognition-dataset-jonathan-oheix_female_asian_adult.jpg', '387_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '201_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '103_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '430_chicago-faces_female_adult_black.jpg', '120_kaggle__zawarkhan69__human-facial-expression-dataset_female_adult_white.jpg', '456_chicago-faces_female_adult_hispanic.jpg', '38_UTK-sanjaya_female_asian_adult.jpg', '359_chicago-faces_male_adult_asian.jpg', '133_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '148_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_old.jpg', '473_chicago-faces_female_adult_white.jpg', '72_chicago-faces_male_adult_white.jpg', '213_chicago-faces_male_adult_black.jpg', '498_chicago-faces_male_adult_white.jpg', '23_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', '54_chicago-faces_female_adult_white.jpg', '84_chicago-faces_male_adult_white.jpg', '422_face-expression-recognition-dataset-jonathan-oheix_female_white_young.jpg', '439_chicago-faces_female_adult_white.jpg', '206_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_young.jpg', '164_chicago-faces_female_adult_black.jpg', '139_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '29_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_adult.jpg', '269_chicago-faces_female_adult_black.jpg', '486_chicago-faces_male_adult_asian.jpg', '174_angry-face-expression-recognition-dataset-jonathan-oheix_male_asian_old.jpg', '327_chicago-faces_female_adult_white.jpg', '21_MMA-FACIAL-EXPRESSION-mahmoud_male_white_old.jpg', '304_chicago-faces_male_adult_white.jpg', '7_focused-face-FER-2013-luis-MANAS-SAMBARE_male_asian_adult.jpg', '182_angry-face-expression-recognition-dataset-jonathan-oheix_male_asian_adult.jpg', '261_chicago-faces_male_adult_black.jpg', '469_chicago-faces_male_adult_asian.jpg', '107_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', '336_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '86_angry-face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '388_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '229_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '61_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '158_chicago-faces_male_adult_white.jpg', '458_chicago-faces_male_adult_white.jpg', '199_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '292_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '18_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '6_chicago-faces_female_adult_black.jpg', '28_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '357_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_young.jpg', '389_chicago-faces_female_adult_white.jpg', '498_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '159_angry-face-expression-recognition-dataset-jonathan-oheix_male_black_adult.jpg', '6_UTK-sanjaya_male_white_adult.jpg', '56_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '310_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '400_chicago-faces_female_adult_black.jpg', '470_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '479_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '114_chicago-faces_female_adult_black.jpg', '48_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '178_MMA-FACIAL-EXPRESSION-mahmoud_female_white_adult.jpg', '103_MMA-FACIAL-EXPRESSION-mahmoud_male_white_old.jpg', '114_MMA-FACIAL-EXPRESSION-mahmoud_female_asian_adult.jpg', '15_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '155_angry-face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '197_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '252_chicago-faces_female_adult_white.jpg', '149_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '454_chicago-faces_male_adult_asian.jpg', '57_angry-face-expression-recognition-dataset-jonathan-oheix_male_other_race_old.jpg', '74_chicago-faces_female_adult_white.jpg', '157_chicago-faces_female_adult_asian.jpg', '301_chicago-faces_female_adult_white.jpg', '247_chicago-faces_female_adult_white.jpg', '56_UTK-sanjaya_male_asian_adult.jpg', '203_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '227_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '42_chicago-faces_female_adult_black.jpg', '90_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '467_chicago-faces_male_adult_black.jpg', '153_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '209_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '134_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '83_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '64_angry-face-expression-recognition-dataset-jonathan-oheix_male_other_race_adult.jpg', '3_human-facial-expression-dataset_female_white_adult.jpg', '119_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '118_chicago-faces_male_adult_black.jpg', '189_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_old.jpg', '239_chicago-faces_female_adult_black.jpg', '255_chicago-faces_female_adult_hispanic.jpg', '174_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '189_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '258_chicago-faces_female_adult_black.jpg', '74_MMA-FACIAL-EXPRESSION-mahmoud_female_asian_adult.jpg', '109_chicago-faces_female_adult_white.jpg', '58_chicago-faces_male_adult_white.jpg', '0_focused-face-FER-2013-luis-MANAS-SAMBARE_male_hispanic_adult.jpg', '253_chicago-faces_male_adult_black.jpg', '1_chicago-faces_female_adult_black.jpg', '251_chicago-faces_female_adult_black.jpg', '89_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_adult.jpg', '14_UTK-sanjaya_male_black_adult.jpg', '374_chicago-faces_female_adult_white.jpg', '10_human-facial-expression-dataset_male_white_adult.jpg', '413_chicago-faces_female_adult_hispanic.jpg', '4_focused-face-FER-2013-luis-MANAS-SAMBARE_male_black_old.jpg', '331_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '171_MMA-FACIAL-EXPRESSION-mahmoud_male_black_old.jpg', '8_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '365_face-expression-recognition-dataset-jonathan-oheix_male_white_young.jpg', '463_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '207_chicago-faces_female_adult_black.jpg', '308_chicago-faces_male_adult_white.jpg', '265_chicago-faces_female_adult_black.jpg', '34_UTK-sanjaya_female_white_adult.jpg', '66_chicago-faces_female_adult_white.jpg', '156_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', '305_chicago-faces_female_adult_asian.jpg', '299_face-expression-recognition-dataset-jonathan-oheix_male_white_young.jpg', '116_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '201_face-expression-recognition-dataset-jonathan-oheix_female_white_young.jpg', '441_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg']\n"
     ]
    }
   ],
   "source": [
    "# add images of each category into an array\n",
    "\n",
    "\n",
    "images_dict, image_name_dict = flatten_images() \n",
    "\n",
    "# tokensize labels\n",
    "labels = {'focused': 0,\n",
    "          'happy': 1,\n",
    "          'neutral': 2,\n",
    "          'surprised': 3}\n",
    "\n",
    "\n",
    "# concatencate all the data with respective labels\n",
    "x = []\n",
    "y = []\n",
    "for key in images_dict:\n",
    "    for image in images_dict[key]:\n",
    "        x.append(image)\n",
    "        y.append(labels[key])\n",
    "x_name = []\n",
    "y_name = []\n",
    "for key in image_name_dict:\n",
    "    for image_name in image_name_dict[key]:\n",
    "        x_name.append(image_name)\n",
    "        y_name.append(labels[key])\n",
    "\n",
    "\n",
    "# split into training and valid/testing\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(x, y, test_size =0.30, random_state=42, stratify=y)\n",
    "x_train_name, x_temp_name, y_train_name, y_temp_name = train_test_split(x_name, y_name, test_size =0.30, random_state=42, stratify=y_name)\n",
    "\n",
    "# split x_temp and y_temp into validation and testing\\\n",
    "x_valid, x_test, y_valid, y_test = train_test_split(x_temp, y_temp, test_size =0.50, random_state=42, stratify=y_temp)\n",
    "x_valid_name, x_test_name, y_valid_name, y_test_name = train_test_split(x_temp_name, y_temp_name, test_size =0.50, random_state=42, stratify=y_temp_name)\n",
    "\n",
    "print(x_test_name)\n",
    "# add all elements of x_test_name into a .txt file\n",
    "with open('test_set_images_categories.txt', 'w') as f:\n",
    "    for item in x_test_name:\n",
    "        # if it's the last item\n",
    "        if item == x_test_name[-1]:\n",
    "            f.write(\"%s\" % item)\n",
    "        else:\n",
    "            f.write(\"%s,\" % item)\n",
    "\n",
    "# augment the data\n",
    "x_train, y_train = augment(x_train, y_train)\n",
    "x_valid, y_valid = augment(x_valid, y_valid)\n",
    "x_test, y_test = augment(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "[  0  52 107 163 216 274 330 388 441 496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2805/128462531.py:46: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400441250/work/torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  images_tensor = torch.tensor(x_train, dtype=torch.float32, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "[  0  55 112 166 226 279 337 393 451 508]\n",
      "--------------------------------\n",
      "[  0  54 108 160 216 276 330 387 448 503]\n",
      "--------------------------------\n",
      "[  0  55 110 164 220 273 333 391 446 503]\n",
      "--------------------------------\n",
      "[  0  54 107 169 226 278 339 393 448 500]\n",
      "--------------------------------\n",
      "[  1  63 129 184 243 297 352 407 462 514]\n",
      "--------------------------------\n",
      "[  0  54 112 165 219 273 324 379 434 490]\n",
      "--------------------------------\n",
      "[  0  59 110 168 221 275 330 384 438 494]\n",
      "--------------------------------\n",
      "[  0  55 106 164 218 274 328 379 433 490]\n",
      "--------------------------------\n",
      "[  0  56 111 165 223 278 332 388 444 500]\n"
     ]
    }
   ],
   "source": [
    "if (enable_kfold):\n",
    "    # use k-fold cross validation to split the data\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    i = 1\n",
    "    for train_index, test_index in kf.split(x):\n",
    "\n",
    "        # print(f\"Fold {i}:\")\n",
    "        # print(f\"  Train: index={train_index}\")\n",
    "        # split into training and valid/testing\n",
    "\n",
    "        #convert x and y to numpy arrays\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "        x_name = np.array(x_name)\n",
    "        y_name = np.array(y_name)\n",
    "\n",
    "\n",
    "        #select the indices for the training and testing data\n",
    "        x_train, x_temp  = x[train_index], x[test_index]\n",
    "        y_train, y_temp  = y[train_index], y[test_index]\n",
    "        x_train_name, x_temp_name  = x_name[train_index], x_name[test_index]\n",
    "        y_train_name, y_temp_name  = y_name[train_index], y_name[test_index]\n",
    "\n",
    "        \n",
    "        #print first 10 elements of x_train\n",
    "        print(\"--------------------------------\")\n",
    "        print(train_index[[0,50,100,150,200,250,300,350,400,450]])\n",
    "\n",
    "        # split x_temp and y_temp into validation and testing\\\n",
    "        x_valid, x_test, y_valid, y_test = train_test_split(x_temp, y_temp, test_size =0.50, random_state=42, stratify=y_temp)\n",
    "        x_valid_name, x_test_name, y_valid_name, y_test_name = train_test_split(x_temp_name, y_temp_name, test_size =0.50, random_state=42, stratify=y_temp_name)\n",
    "\n",
    "\n",
    "        # augment the data\n",
    "        x_train, y_train = augment(x_train, y_train)\n",
    "        x_valid, y_valid = augment(x_valid, y_valid)\n",
    "        x_test, y_test = augment(x_test, y_test)\n",
    "\n",
    "\n",
    "        #Create data that can be fed into pytorch\n",
    "\n",
    "        #getting device type\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        #training\n",
    "        images_tensor = torch.tensor(x_train, dtype=torch.float32, device=device)\n",
    "        images_tensor = images_tensor.unsqueeze(1)\n",
    "        labels_tensor = torch.tensor(y_train, dtype=torch.long, device=device)\n",
    "\n",
    "        # validation\n",
    "        images_valid_tensor = torch.tensor(x_valid, dtype=torch.float32, device=device)\n",
    "        images_valid_tensor = images_valid_tensor.unsqueeze(1)\n",
    "        labels_valid_tensor = torch.tensor(y_valid, dtype=torch.long, device=device)\n",
    "\n",
    "        # testing\n",
    "        images_testing_tensor = torch.tensor(x_test, dtype=torch.float32, device=device)\n",
    "        images_testing_tensor = images_testing_tensor.unsqueeze(1)\n",
    "        labels_testing_tensor = torch.tensor(y_test, dtype=torch.long, device=device)\n",
    "\n",
    "        batch_size = 2048\n",
    "\n",
    "        # Create a TensorDataset\n",
    "        # training\n",
    "        dataset_train = td.TensorDataset(images_tensor, labels_tensor)\n",
    "        data_loader = td.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "        # validation\n",
    "        dataset_valid = td.TensorDataset(images_valid_tensor, labels_valid_tensor)\n",
    "        valid_loader = td.DataLoader(dataset_valid, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "        # testing\n",
    "        dataset_test = td.TensorDataset(images_testing_tensor, labels_testing_tensor)\n",
    "        test_loader = td.DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "        # # save each dataset\n",
    "        # torch.save(dataset_train, 'dataset_train.pt')\n",
    "        # torch.save(dataset_valid, 'dataset_valid.pt')\n",
    "        # torch.save(dataset_test, 'dataset_test.pt')\n",
    "\n",
    "        #save loaders\n",
    "        torch.save(data_loader, 'kfolds/data_loader_kfold%s.pt'%(i))\n",
    "        torch.save(valid_loader, 'kfolds/valid_loader_kfold%s.pt'%(i))\n",
    "        torch.save(test_loader, 'kfolds/test_loader_kfold%s.pt'%(i))\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters and settings\n",
    "batch_size = 64\n",
    "test_batch_size = 64\n",
    "input_size = 1 # because there is only one channel \n",
    "output_size = 4\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_image(arr_in):\n",
    "    for directory in ['focused', 'happy', 'neutral', 'surprised']:\n",
    "                images = os.listdir(\"../concat_data/%s\" % directory)\n",
    "                #Iterate through the images\n",
    "                for image in images:\n",
    "                    #check extension of the image\n",
    "                    if image.split(\".\")[-1] == \"jpg\":\n",
    "                        #Read the image\n",
    "                        img = cv2.imread(\"../concat_data/%s/%s\" %(directory, image), 0)\n",
    "                        #Flatten the image\n",
    "                        # img = img.flatten()\n",
    "                        #Add the flattened image to the list\n",
    "                        if np.array_equal(img, arr_in):\n",
    "                            # \n",
    "                            print(image)\n",
    "                            print(directory)\n",
    "                            return image, directory\n",
    "                            \n",
    "         \n",
    "    return None\n",
    "def find_respective_images(tensor_in):\n",
    "    # finds the image in the one of the directories\n",
    "    # tensor_in: tensor\n",
    "    # return: string\n",
    "    dict_out = {'focused': [], 'happy': [], 'neutral': [], 'surprised': []}\n",
    "\n",
    "    #Get the list of images in the directory\n",
    "    for element in tensor_in:\n",
    "        for element_name in element:\n",
    "            numpy_tensor = element_name.numpy()\n",
    "            image, directory = find_image(numpy_tensor)\n",
    "            dict_out[directory].append(image)\n",
    "\n",
    "            \n",
    "    \n",
    "    # print(tensor_in.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Create data that can be fed into pytorch\n",
    "\n",
    "#getting device type\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#training\n",
    "images_tensor = torch.tensor(x_train, dtype=torch.float32, device=device)\n",
    "images_tensor = images_tensor.unsqueeze(1)\n",
    "labels_tensor = torch.tensor(y_train, dtype=torch.long, device=device)\n",
    "\n",
    "# validation\n",
    "images_valid_tensor = torch.tensor(x_valid, dtype=torch.float32, device=device)\n",
    "images_valid_tensor = images_valid_tensor.unsqueeze(1)\n",
    "labels_valid_tensor = torch.tensor(y_valid, dtype=torch.long, device=device)\n",
    "\n",
    "# testing\n",
    "images_testing_tensor = torch.tensor(x_test, dtype=torch.float32, device=device)\n",
    "images_testing_tensor = images_testing_tensor.unsqueeze(1)\n",
    "labels_testing_tensor = torch.tensor(y_test, dtype=torch.long, device=device)\n",
    "\n",
    "batch_size = 2048\n",
    "\n",
    "# Create a TensorDataset\n",
    "# training\n",
    "dataset_train = td.TensorDataset(images_tensor, labels_tensor)\n",
    "data_loader = td.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# validation\n",
    "dataset_valid = td.TensorDataset(images_valid_tensor, labels_valid_tensor)\n",
    "valid_loader = td.DataLoader(dataset_valid, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# testing\n",
    "dataset_test = td.TensorDataset(images_testing_tensor, labels_testing_tensor)\n",
    "test_loader = td.DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# # save each dataset\n",
    "# torch.save(dataset_train, 'dataset_train.pt')\n",
    "# torch.save(dataset_valid, 'dataset_valid.pt')\n",
    "# torch.save(dataset_test, 'dataset_test.pt')\n",
    "\n",
    "#save loaders\n",
    "torch.save(data_loader, 'data_loader.pt')\n",
    "torch.save(valid_loader, 'valid_loader.pt')\n",
    "torch.save(test_loader, 'test_loader.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_unique_sets():\n",
    "    for name in x_test_name:\n",
    "        if (name in x_valid_name) or (name in x_train_name):\n",
    "            print(name)\n",
    "            print(\"error\")\n",
    "    for name in x_valid_name:\n",
    "        if (name in x_test_name) or (name in x_train_name):\n",
    "            print(name)\n",
    "            print(\"error\")\n",
    "    for name in x_train_name:\n",
    "        if (name in x_valid_name) or (name in x_test_name):\n",
    "            print(name)\n",
    "            print(\"error\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
