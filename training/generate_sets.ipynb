{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as td\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_open = \"../concat_data_tagged/\"\n",
    "enable_kfold = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Takes images in concat_data and flatten them into a 1D array\n",
    "def flatten_images():\n",
    "    images_dict = {'focused': [],\n",
    "                    'happy': [],\n",
    "                    'neutral': [],\n",
    "                    'surprised': []}\n",
    "    image_name_dict = {'focused': [],\n",
    "                    'happy': [],\n",
    "                    'neutral': [],\n",
    "                    'surprised': []}\n",
    "    \n",
    "    for category in ['focused', 'happy', 'neutral', 'surprised']:\n",
    "        #Get the list of images in the directory\n",
    "        images = os.listdir(path_to_open + \"%s\" % category)\n",
    "        #Create an empty list to store the flattened images\n",
    "        flattened_images = []\n",
    "        #Iterate through the images\n",
    "        \n",
    "        for image in images:\n",
    "            #check extension of the image\n",
    "            if image.split(\".\")[-1] == \"jpg\":\n",
    "                #Read the image\n",
    "                img = cv2.imread(path_to_open + \"%s/%s\" %(category, image), 0)\n",
    "                #Flatten the image\n",
    "                # img = img.flatten()\n",
    "                #Add the flattened image to the list\n",
    "                images_dict[category].append(img)\n",
    "                image_name_dict[category].append(category + \"_\" + image)\n",
    "\n",
    "\n",
    "    #Return the list of flattened images\n",
    "    return images_dict, image_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation functions\n",
    "\n",
    "def flip(image):\n",
    "    return cv2.flip(image, 1) # flipping around y-axis\n",
    "\n",
    "def rotate(image):\n",
    "    angle = np.random.uniform(-5,5)\n",
    "    M = cv2.getRotationMatrix2D((image.shape[1] / 2, image.shape[0] / 2), angle, 1)\n",
    "    return cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "def brighten(image):\n",
    "    grey = False\n",
    "    if len(image.shape) == 2:\n",
    "        grey = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    factor = np.random.uniform(0.5, 1.5)\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hsv[:,:,2] = np.clip(hsv[:,:,2] * factor, 0, 255)\n",
    "    bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR) \n",
    "    return bgr if not grey else cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "def change_contrast(image):\n",
    "    factor = np.random.uniform(0.5, 1.5)\n",
    "    return cv2.convertScaleAbs(image, alpha=factor, beta=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(images, labels):\n",
    "    augmented_images = []\n",
    "    augmented_labels = []\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        image = images[i]\n",
    "        label = labels[i]\n",
    "\n",
    "        # save original image\n",
    "        augmented_images.append(image)\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "        # flipping\n",
    "        augmented_images.append(flip(image))\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "        # rotating\n",
    "        augmented_images.append(rotate(image))\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "        # brightening\n",
    "        augmented_images.append(brighten(image))\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "        # changing contrast\n",
    "        augmented_images.append(change_contrast(image))\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "    return augmented_images, augmented_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add images of each category into an array\n",
    "\n",
    "\n",
    "images_dict, image_name_dict = flatten_images() \n",
    "\n",
    "# tokensize labels\n",
    "labels = {'focused': 0,\n",
    "          'happy': 1,\n",
    "          'neutral': 2,\n",
    "          'surprised': 3}\n",
    "\n",
    "\n",
    "# concatencate all the data with respective labels\n",
    "x = []\n",
    "y = []\n",
    "for key in images_dict:\n",
    "    for image in images_dict[key]:\n",
    "        x.append(image)\n",
    "        y.append(labels[key])\n",
    "x_name = []\n",
    "y_name = []\n",
    "for key in image_name_dict:\n",
    "    for image_name in image_name_dict[key]:\n",
    "        x_name.append(image_name)\n",
    "        y_name.append(labels[key])\n",
    "\n",
    "\n",
    "# split into training and valid/testing\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(x, y, test_size =0.30, random_state=42, stratify=y)\n",
    "x_train_name, x_temp_name, y_train_name, y_temp_name = train_test_split(x_name, y_name, test_size =0.30, random_state=42, stratify=y_name)\n",
    "\n",
    "# split x_temp and y_temp into validation and testing\\\n",
    "x_valid, x_test, y_valid, y_test = train_test_split(x_temp, y_temp, test_size =0.50, random_state=42, stratify=y_temp)\n",
    "x_valid_name, x_test_name, y_valid_name, y_test_name = train_test_split(x_temp_name, y_temp_name, test_size =0.50, random_state=42, stratify=y_temp_name)\n",
    "\n",
    "# augment the data\n",
    "x_train, y_train = augment(x_train, y_train)\n",
    "x_valid, y_valid = augment(x_valid, y_valid)\n",
    "x_test, y_test = augment(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[   0    1    2 ... 6997 6998 6999]\n",
      "Fold 1:\n",
      "  Train: index=[   0    1    2 ... 6997 6998 6999]\n",
      "Fold 2:\n",
      "  Train: index=[   0    1    2 ... 6995 6998 6999]\n",
      "Fold 3:\n",
      "  Train: index=[   0    1    2 ... 6997 6998 6999]\n",
      "Fold 4:\n",
      "  Train: index=[   0    1    2 ... 6996 6997 6998]\n",
      "Fold 5:\n",
      "  Train: index=[   1    2    3 ... 6996 6997 6999]\n",
      "Fold 6:\n",
      "  Train: index=[   0    1    2 ... 6997 6998 6999]\n",
      "Fold 7:\n",
      "  Train: index=[   0    3    4 ... 6997 6998 6999]\n",
      "Fold 8:\n",
      "  Train: index=[   0    1    2 ... 6997 6998 6999]\n",
      "Fold 9:\n",
      "  Train: index=[   0    1    2 ... 6997 6998 6999]\n",
      "KFold(n_splits=10, random_state=42, shuffle=True)\n",
      "<generator object _BaseKFold.split at 0x0000029CC5229D80>\n"
     ]
    }
   ],
   "source": [
    "if (enable_kfold):\n",
    "    # use k-fold cross validation to split the data\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    x_train_split = kf.split(x_train)\n",
    "    for i, (train_index, test_index) in enumerate(x_train_split):\n",
    "        print(f\"Fold {i}:\")\n",
    "        print(f\"  Train: index={train_index}\")\n",
    "\n",
    "        # print(f\"  Test:  index={test_index}\")\n",
    "\n",
    "print(kf)\n",
    "print(kf.split(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters and settings\n",
    "batch_size = 64\n",
    "test_batch_size = 64\n",
    "input_size = 1 # because there is only one channel \n",
    "output_size = 4\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_image(arr_in):\n",
    "    for directory in ['focused', 'happy', 'neutral', 'surprised']:\n",
    "                images = os.listdir(\"../concat_data/%s\" % directory)\n",
    "                #Iterate through the images\n",
    "                for image in images:\n",
    "                    #check extension of the image\n",
    "                    if image.split(\".\")[-1] == \"jpg\":\n",
    "                        #Read the image\n",
    "                        img = cv2.imread(\"../concat_data/%s/%s\" %(directory, image), 0)\n",
    "                        #Flatten the image\n",
    "                        # img = img.flatten()\n",
    "                        #Add the flattened image to the list\n",
    "                        if np.array_equal(img, arr_in):\n",
    "                            # \n",
    "                            print(image)\n",
    "                            print(directory)\n",
    "                            return image, directory\n",
    "                            \n",
    "         \n",
    "    return None\n",
    "def find_respective_images(tensor_in):\n",
    "    # finds the image in the one of the directories\n",
    "    # tensor_in: tensor\n",
    "    # return: string\n",
    "    dict_out = {'focused': [], 'happy': [], 'neutral': [], 'surprised': []}\n",
    "\n",
    "    #Get the list of images in the directory\n",
    "    for element in tensor_in:\n",
    "        for element_name in element:\n",
    "            numpy_tensor = element_name.numpy()\n",
    "            image, directory = find_image(numpy_tensor)\n",
    "            dict_out[directory].append(image)\n",
    "\n",
    "            \n",
    "    \n",
    "    # print(tensor_in.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luis\\AppData\\Local\\Temp\\ipykernel_1468\\3321851491.py:7: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "  images_tensor = torch.tensor(x_train, dtype=torch.float32, device=device)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Create data that can be fed into pytorch\n",
    "\n",
    "#getting device type\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#training\n",
    "images_tensor = torch.tensor(x_train, dtype=torch.float32, device=device)\n",
    "images_tensor = images_tensor.unsqueeze(1)\n",
    "labels_tensor = torch.tensor(y_train, dtype=torch.long, device=device)\n",
    "\n",
    "# validation\n",
    "images_valid_tensor = torch.tensor(x_valid, dtype=torch.float32, device=device)\n",
    "images_valid_tensor = images_valid_tensor.unsqueeze(1)\n",
    "labels_valid_tensor = torch.tensor(y_valid, dtype=torch.long, device=device)\n",
    "\n",
    "# testing\n",
    "images_testing_tensor = torch.tensor(x_test, dtype=torch.float32, device=device)\n",
    "images_testing_tensor = images_testing_tensor.unsqueeze(1)\n",
    "labels_testing_tensor = torch.tensor(y_test, dtype=torch.long, device=device)\n",
    "\n",
    "batch_size = 2048\n",
    "\n",
    "# Create a TensorDataset\n",
    "# training\n",
    "dataset_train = td.TensorDataset(images_tensor, labels_tensor)\n",
    "data_loader = td.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# validation\n",
    "dataset_valid = td.TensorDataset(images_valid_tensor, labels_valid_tensor)\n",
    "valid_loader = td.DataLoader(dataset_valid, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# testing\n",
    "dataset_test = td.TensorDataset(images_testing_tensor, labels_testing_tensor)\n",
    "test_loader = td.DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# # save each dataset\n",
    "# torch.save(dataset_train, 'dataset_train.pt')\n",
    "# torch.save(dataset_valid, 'dataset_valid.pt')\n",
    "# torch.save(dataset_test, 'dataset_test.pt')\n",
    "\n",
    "#save loaders\n",
    "torch.save(data_loader, 'data_loader.pt')\n",
    "torch.save(valid_loader, 'valid_loader.pt')\n",
    "torch.save(test_loader, 'test_loader.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_unique_sets():\n",
    "    for name in x_test_name:\n",
    "        if (name in x_valid_name) or (name in x_train_name):\n",
    "            print(name)\n",
    "            print(\"error\")\n",
    "    for name in x_valid_name:\n",
    "        if (name in x_test_name) or (name in x_train_name):\n",
    "            print(name)\n",
    "            print(\"error\")\n",
    "    for name in x_train_name:\n",
    "        if (name in x_valid_name) or (name in x_test_name):\n",
    "            print(name)\n",
    "            print(\"error\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
