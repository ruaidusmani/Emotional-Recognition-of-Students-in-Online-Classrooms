{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as td\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_open = \"../concat_data_tagged/\"\n",
    "enable_kfold = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Takes images in concat_data and flatten them into a 1D array\n",
    "def flatten_images():\n",
    "    images_dict = {'focused': [],\n",
    "                    'happy': [],\n",
    "                    'neutral': [],\n",
    "                    'surprised': []}\n",
    "    image_name_dict = {'focused': [],\n",
    "                    'happy': [],\n",
    "                    'neutral': [],\n",
    "                    'surprised': []}\n",
    "    \n",
    "    for category in ['focused', 'happy', 'neutral', 'surprised']:\n",
    "        #Get the list of images in the directory\n",
    "        images = os.listdir(path_to_open + \"%s\" % category)\n",
    "        #Create an empty list to store the flattened images\n",
    "        flattened_images = []\n",
    "        #Iterate through the images\n",
    "        \n",
    "        for image in images:\n",
    "            #check extension of the image\n",
    "            if image.split(\".\")[-1] == \"jpg\":\n",
    "                #Read the image\n",
    "                img = cv2.imread(path_to_open + \"%s/%s\" %(category, image), 0)\n",
    "                #Flatten the image\n",
    "                # img = img.flatten()\n",
    "                #Add the flattened image to the list\n",
    "                images_dict[category].append(img)\n",
    "                # image_name_dict[category].append(category + \"_\" + image)\n",
    "                image_name_dict[category].append(image)\n",
    "\n",
    "\n",
    "    #Return the list of flattened images\n",
    "    return images_dict, image_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_image(image_path):\n",
    "    img = cv2.imread(image_path, 0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation functions\n",
    "\n",
    "def flip(image):\n",
    "    return cv2.flip(image, 1) # flipping around y-axis\n",
    "\n",
    "def rotate(image):\n",
    "    angle = np.random.uniform(-5,5)\n",
    "    M = cv2.getRotationMatrix2D((image.shape[1] / 2, image.shape[0] / 2), angle, 1)\n",
    "    return cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "def brighten(image):\n",
    "    grey = False\n",
    "    if len(image.shape) == 2:\n",
    "        grey = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    factor = np.random.uniform(0.5, 1.5)\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hsv[:,:,2] = np.clip(hsv[:,:,2] * factor, 0, 255)\n",
    "    bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR) \n",
    "    return bgr if not grey else cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "def change_contrast(image):\n",
    "    factor = np.random.uniform(0.5, 1.5)\n",
    "    return cv2.convertScaleAbs(image, alpha=factor, beta=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(images, labels):\n",
    "    augmented_images = []\n",
    "    augmented_labels = []\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        image = images[i]\n",
    "        label = labels[i]\n",
    "\n",
    "        # save original image\n",
    "        augmented_images.append(image)\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "        # flipping\n",
    "        augmented_images.append(flip(image))\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "        # rotating\n",
    "        augmented_images.append(rotate(image))\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "        # brightening\n",
    "        augmented_images.append(brighten(image))\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "        # changing contrast\n",
    "        augmented_images.append(change_contrast(image))\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "    return augmented_images, augmented_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['157_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '311_chicago-faces_male_adult_white.jpg', '125_chicago-faces_male_adult_black.jpg', '22_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '13_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '3_chicago-faces_male_adult_white.jpg', '87_chicago-faces_female_adult_white.jpg', '84_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_young.jpg', '191_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '92_face-expression-recognition-dataset-jonathan-oheix_female_black_adult.jpg', '124_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '117_face-expression-recognition-dataset-jonathan-oheix_female_black_adult.jpg', '74_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '142_face-expression-recognition-dataset-jonathan-oheix_male_white_young.jpg', '210_chicago-faces_female_adult_white.jpg', '180_MMA-FACIAL-EXPRESSION-mahmoud_male_asian_adult.jpg', '376_face-expression-recognition-dataset-jonathan-oheix_male_white_young.jpg', '123_chicago-faces_male_adult_black.jpg', '141_chicago-faces_male_adult_white.jpg', '509_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '60_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '64_MMA-FACIAL-EXPRESSION-mahmoud_male_black_adult.jpg', '72_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '34_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', '167_face-expression-recognition-dataset-jonathan-oheix_female_white_young.jpg', '235_face-expression-recognition-dataset-jonathan-oheix_male_asian_adult.jpg', '36_MMA-FACIAL-EXPRESSION-mahmoud_male_asian_adult.jpg', '101_MMA-FACIAL-EXPRESSION-mahmoud_male_black_adult.jpg', '88_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '134_MMA-FACIAL-EXPRESSION-mahmoud_male_white_old.jpg', '151_chicago-faces_other_gender_adult_black.jpg', '240_chicago-faces_male_adult_white.jpg', '209_chicago-faces_male_adult_white.jpg', '103_chicago-faces_female_adult_black.jpg', '183_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '39_chicago-faces_male_adult_asian.jpg', '255_chicago-faces_male_adult_black.jpg', '432_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_young.jpg', '53_chicago-faces_male_adult_white.jpg', '406_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '11_UTK-sanjaya_female_white_adult.jpg', '80_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '47_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '16_angry-face-expression-recognition-dataset-jonathan-oheix_female_asian_adult.jpg', '95_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', '188_angry-face-expression-recognition-dataset-jonathan-oheix_female_white_young.jpg', '164_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '43_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '153_chicago-faces_female_adult_black.jpg', '256_chicago-faces_female_adult_black.jpg', '73_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '504_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '0_chicago-faces_female_adult_asian.jpg', '17_focused-face-FER-2013-luis-MANAS-SAMBARE_male_white_adult.jpg', '480_chicago-faces_female_adult_black.jpg', '65_chicago-faces_male_adult_black.jpg', '22_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '7_chicago-faces_male_adult_white.jpg', '320_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '21_chicago-faces_male_adult_white.jpg', '34_angry-face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '52_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '123_MMA-FACIAL-EXPRESSION-mahmoud_female_asian_adult.jpg', '13_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '2_human-facial-expression-dataset_male_white_adult.jpg', '52_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '186_angry-face-expression-recognition-dataset-jonathan-oheix_male_black_adult.jpg', '512_face-expression-recognition-dataset-jonathan-oheix_male_white_young.jpg', '58_chicago-faces_male_adult_white.jpg', '451_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_young.jpg', '396_chicago-faces_male_adult_asian.jpg', '327_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '44_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_old.jpg', '67_chicago-faces_male_adult_black.jpg', '60_chicago-faces_female_adult_asian.jpg', '438_chicago-faces_male_adult_asian.jpg', '414_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '205_chicago-faces_male_adult_asian.jpg', '136_face-expression-recognition-dataset-jonathan-oheix_female_white_young.jpg', '95_chicago-faces_female_adult_asian.jpg', '234_chicago-faces_female_adult_white.jpg', '50_angry-face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '154_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '466_chicago-faces_female_adult_white.jpg', '164_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '120_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_old.jpg', '104_angry-face-expression-recognition-dataset-jonathan-oheix_male_hispanic_adult.jpg', '38_chicago-faces_male_adult_asian.jpg', '14_UTK-sanjaya_male_black_adult.jpg', '48_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '9_chicago-faces_female_adult_white.jpg', '142_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_hispanic.jpg', '301_chicago-faces_female_adult_white.jpg', '424_chicago-faces_female_adult_asian.jpg', '185_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_old.jpg', '187_chicago-faces_female_adult_black.jpg', '70_chicago-faces_male_adult_white.jpg', '122_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '90_angry-face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '107_face-expression-recognition-dataset-jonathan-oheix_female_black_adult.jpg', '517_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '85_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '165_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '20_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '168_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '94_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '213_chicago-faces_male_adult_black.jpg', '19_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '133_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '372_chicago-faces_female_adult_hispanic.jpg', '60_chicago-faces_female_adult_hispanic.jpg', '8_face-expression-recognition-dataset-jonathan-oheix_male_white_young.jpg', '88_chicago-faces_male_adult_asian.jpg', '304_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '237_chicago-faces_female_adult_asian.jpg', '219_chicago-faces_female_adult_asian.jpg', '312_chicago-faces_male_adult_white.jpg', '66_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '274_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '106_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '175_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', '92_chicago-faces_male_adult_white.jpg', '83_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '113_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '202_chicago-faces_female_adult_white.jpg', '62_chicago-faces_male_adult_hispanic.jpg', '374_chicago-faces_female_adult_white.jpg', '251_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '278_chicago-faces_female_adult_black.jpg', '222_chicago-faces_female_adult_black.jpg', '147_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '378_chicago-faces_female_adult_asian.jpg', '392_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '3_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '56_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', '466_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '68_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '188_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '64_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '245_face-expression-recognition-dataset-jonathan-oheix_male_white_young.jpg', '175_chicago-faces_male_adult_asian.jpg', '65_MMA-FACIAL-EXPRESSION-mahmoud_female_asian_adult.jpg', '242_chicago-faces_female_adult_black.jpg', '117_chicago-faces_male_adult_asian.jpg', '23_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '79_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '227_chicago-faces_male_adult_black.jpg', '56_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '176_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '502_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '350_face-expression-recognition-dataset-jonathan-oheix_male_white_young.jpg', '38_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '35_UTK-sanjaya_female_white_adult.jpg', '184_chicago-faces_female_adult_white.jpg', '216_chicago-faces_female_adult_asian.jpg', '463_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '11_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '99_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_black.jpg', '156_chicago-faces_female_adult_asian.jpg', '250_chicago-faces_male_adult_black.jpg', '461_chicago-faces_female_adult_black.jpg', '355_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_young.jpg', '168_chicago-faces_male_adult_black.jpg', '180_chicago-faces_male_adult_hispanic.jpg', '176_angry-face-expression-recognition-dataset-jonathan-oheix_male_black_adult.jpg', '228_chicago-faces_female_adult_hispanic.jpg', '105_chicago-faces_female_adult_black.jpg', '200_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '431_face-expression-recognition-dataset-jonathan-oheix_other_gender_black_young.jpg', '42_chicago-faces_male_adult_white.jpg', '83_MMA-FACIAL-EXPRESSION-mahmoud_male_white_old.jpg', '155_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '130_chicago-faces_male_adult_black.jpg', '22_chicago-faces_male_adult_white.jpg', '153_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_young.jpg', '44_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', '91_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '472_chicago-faces_female_adult_asian.jpg', '41_face-expression-recognition-dataset-jonathan-oheix_male_white_young.jpg', '199_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '19_focused-face-FER-2013-luis-MANAS-SAMBARE_male_white_old.jpg', '257_chicago-faces_male_adult_white.jpg', '78_chicago-faces_female_adult_black.jpg', '94_chicago-faces_male_adult_white.jpg', '389_chicago-faces_female_adult_white.jpg', '31_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', '399_chicago-faces_female_adult_white.jpg', '150_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '21_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '417_chicago-faces_male_adult_black.jpg', '490_chicago-faces_female_adult_white.jpg', '215_chicago-faces_female_adult_white.jpg', '248_chicago-faces_female_adult_asian.jpg', '3_UTK-sanjaya_male_white_adult.jpg', '83_chicago-faces_female_adult_hispanic.jpg', '302_chicago-faces_female_adult_white.jpg', '452_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '260_chicago-faces_male_adult_white.jpg', '101_face-expression-recognition-dataset-jonathan-oheix_female_black_adult.jpg', '58_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '252_chicago-faces_female_adult_white.jpg', '213_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '447_chicago-faces_female_adult_black.jpg', '342_chicago-faces_female_adult_hispanic.jpg', '11_focused-face-FER-2013-luis-MANAS-SAMBARE_female_asian_adult.jpg', '227_chicago-faces_female_adult_white.jpg', '15_human-facial-expression-dataset_male_white_adult.jpg', '178_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '7_human-facial-expression-dataset_female_asian_adult.jpg', '196_angry-face-expression-recognition-dataset-jonathan-oheix_male_other_race_adult.jpg', '132_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '413_chicago-faces_female_adult_hispanic.jpg', '115_MMA-FACIAL-EXPRESSION-mahmoud_male_white_old.jpg', '323_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '111_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '301_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '103_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '0_UTK-sanjaya_female_white_adult.jpg', '137_kaggle__zawarkhan69__human-facial-expression-dataset_female_adult_white.jpg', '33_chicago-faces_female_adult_hispanic.jpg', '344_face-expression-recognition-dataset-jonathan-oheix_female_black_adult.jpg', '19_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '29_chicago-faces_female_adult_white.jpg', '142_chicago-faces_female_adult_white.jpg', '48_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '156_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_adult.jpg', '112_chicago-faces_male_adult_black.jpg', '210_face-expression-recognition-dataset-jonathan-oheix_female_black_adult.jpg', '78_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', '10_human-facial-expression-dataset_male_white_adult.jpg', '499_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '287_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '133_chicago-faces_male_adult_white.jpg', '197_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '491_face-expression-recognition-dataset-jonathan-oheix_male_black_adult.jpg', '23_chicago-faces_female_adult_black.jpg', '78_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '19_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', '32_MMA-FACIAL-EXPRESSION-mahmoud_female_white_adult.jpg', '125_angry-face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '51_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '26_angry-face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '52_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '251_chicago-faces_female_adult_black.jpg', '276_face-expression-recognition-dataset-jonathan-oheix_female_white_old.jpg', '448_chicago-faces_male_adult_asian.jpg', '11_MMA-FACIAL-EXPRESSION-mahmoud_male_black_adult.jpg', '62_chicago-faces_female_adult_white.jpg', '465_chicago-faces_female_adult_white.jpg', '147_chicago-faces_female_adult_white.jpg', '467_chicago-faces_male_adult_black.jpg', '6_UTK-sanjaya_male_white_adult.jpg', '1_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', '481_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '224_chicago-faces_male_adult_asian.jpg', '447_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '443_chicago-faces_male_adult_asian.jpg', '145_chicago-faces_female_adult_asian.jpg', '57_angry-face-expression-recognition-dataset-jonathan-oheix_male_other_race_old.jpg', '129_chicago-faces_female_adult_white.jpg', '117_chicago-faces_female_adult_black.jpg', '45_UTK-sanjaya_male_other_race_adult.jpg', '210_angry-face-expression-recognition-dataset-jonathan-oheix_female_white_old.jpg', '2_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '115_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '60_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_old.jpg', '388_chicago-faces_male_adult_asian.jpg', '244_chicago-faces_female_adult_hispanic.jpg', '76_face-expression-recognition-dataset-jonathan-oheix_female_black_adult.jpg', '144_chicago-faces_female_adult_white.jpg', '221_chicago-faces_female_adult_asian.jpg', '174_angry-face-expression-recognition-dataset-jonathan-oheix_male_asian_old.jpg', '291_chicago-faces_male_adult_white.jpg', '177_chicago-faces_male_adult_white.jpg', '23_UTK-sanjaya_male_white_adult.jpg', '17_chicago-faces_female_adult_black.jpg', '127_kaggle__zawarkhan69__human-facial-expression-dataset_female_old_white.jpg', '118_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', '182_face-expression-recognition-dataset-jonathan-oheix_female_white_young.jpg', '163_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', '255_chicago-faces_female_adult_hispanic.jpg', '20_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', '99_chicago-faces_female_adult_white.jpg', '23_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '518_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '60_UTK-sanjaya_male_white_adult.jpg', '17_human-facial-expression-dataset_female_white_adult.jpg', '330_face-expression-recognition-dataset-jonathan-oheix_female_black_adult.jpg', '90_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', '97_chicago-faces_female_adult_black.jpg', '290_chicago-faces_male_adult_white.jpg', '181_chicago-faces_female_adult_white.jpg', '13_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', '206_chicago-faces_other_gender_adult_black.jpg', '3_focused-face-FER-2013-luis-MANAS-SAMBARE_male_white_adult.jpg', '364_chicago-faces_male_adult_asian.jpg', '61_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', '71_chicago-faces_female_adult_black.jpg', '357_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_young.jpg', '456_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_young.jpg']\n"
     ]
    }
   ],
   "source": [
    "# add images of each category into an array\n",
    "\n",
    "\n",
    "images_dict, image_name_dict = flatten_images() \n",
    "\n",
    "# tokensize labels\n",
    "labels = {'focused': 0,\n",
    "          'happy': 1,\n",
    "          'neutral': 2,\n",
    "          'surprised': 3}\n",
    "\n",
    "\n",
    "# concatencate all the data with respective labels\n",
    "x = []\n",
    "y = []\n",
    "for key in images_dict:\n",
    "    for image in images_dict[key]:\n",
    "        x.append(image)\n",
    "        y.append(labels[key])\n",
    "x_name = []\n",
    "y_name = []\n",
    "for key in image_name_dict:\n",
    "    for image_name in image_name_dict[key]:\n",
    "        x_name.append(image_name)\n",
    "        y_name.append(labels[key])\n",
    "\n",
    "\n",
    "# split into training and valid/testing\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(x, y, test_size =0.30, random_state=42, stratify=y)\n",
    "x_train_name, x_temp_name, y_train_name, y_temp_name = train_test_split(x_name, y_name, test_size =0.30, random_state=42, stratify=y_name)\n",
    "\n",
    "# split x_temp and y_temp into validation and testing\\\n",
    "x_valid, x_test, y_valid, y_test = train_test_split(x_temp, y_temp, test_size =0.50, random_state=42, stratify=y_temp)\n",
    "x_valid_name, x_test_name, y_valid_name, y_test_name = train_test_split(x_temp_name, y_temp_name, test_size =0.50, random_state=42, stratify=y_temp_name)\n",
    "\n",
    "print(x_test_name)\n",
    "# add all elements of x_test_name into a .txt file\n",
    "with open('test_set_images_categories.txt', 'w') as f:\n",
    "    for item in x_test_name:\n",
    "        # if it's the last item\n",
    "        if item == x_test_name[-1]:\n",
    "            f.write(\"%s\" % item)\n",
    "        else:\n",
    "            f.write(\"%s,\" % item)\n",
    "\n",
    "# augment the data\n",
    "x_train, y_train = augment(x_train, y_train)\n",
    "x_valid, y_valid = augment(x_valid, y_valid)\n",
    "x_test, y_test = augment(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "[  0  52 107 163 216 274 330 388 441 496]\n",
      "--------------------------------\n",
      "[  0  55 112 166 226 279 337 393 451 508]\n",
      "--------------------------------\n",
      "[  0  54 108 160 216 276 330 387 448 503]\n",
      "--------------------------------\n",
      "[  0  55 110 164 220 273 333 391 446 503]\n",
      "--------------------------------\n",
      "[  0  54 107 169 226 278 339 393 448 500]\n",
      "--------------------------------\n",
      "[  1  63 129 184 243 297 352 407 462 514]\n",
      "--------------------------------\n",
      "[  0  54 112 165 219 273 324 379 434 490]\n",
      "--------------------------------\n",
      "[  0  59 110 168 221 275 330 384 438 494]\n",
      "--------------------------------\n",
      "[  0  55 106 164 218 274 328 379 433 490]\n",
      "--------------------------------\n",
      "[  0  56 111 165 223 278 332 388 444 500]\n"
     ]
    }
   ],
   "source": [
    "if (enable_kfold):\n",
    "    # use k-fold cross validation to split the data\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    i = 1\n",
    "    for train_index, test_index in kf.split(x):\n",
    "\n",
    "        # print(f\"Fold {i}:\")\n",
    "        # print(f\"  Train: index={train_index}\")\n",
    "        # split into training and valid/testing\n",
    "\n",
    "        #convert x and y to numpy arrays\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "        x_name = np.array(x_name)\n",
    "        y_name = np.array(y_name)\n",
    "\n",
    "\n",
    "        #select the indices for the training and testing data\n",
    "        x_train, x_temp  = x[train_index], x[test_index]\n",
    "        y_train, y_temp  = y[train_index], y[test_index]\n",
    "        x_train_name, x_temp_name  = x_name[train_index], x_name[test_index]\n",
    "        y_train_name, y_temp_name  = y_name[train_index], y_name[test_index]\n",
    "\n",
    "        \n",
    "        #print first 10 elements of x_train\n",
    "        print(\"--------------------------------\")\n",
    "        print(train_index[[0,50,100,150,200,250,300,350,400,450]])\n",
    "\n",
    "        # split x_temp and y_temp into validation and testing\\\n",
    "        x_valid, x_test, y_valid, y_test = train_test_split(x_temp, y_temp, test_size =0.50, random_state=42, stratify=y_temp)\n",
    "        x_valid_name, x_test_name, y_valid_name, y_test_name = train_test_split(x_temp_name, y_temp_name, test_size =0.50, random_state=42, stratify=y_temp_name)\n",
    "\n",
    "\n",
    "        # augment the data\n",
    "        x_train, y_train = augment(x_train, y_train)\n",
    "        x_valid, y_valid = augment(x_valid, y_valid)\n",
    "        x_test, y_test = augment(x_test, y_test)\n",
    "\n",
    "\n",
    "        #Create data that can be fed into pytorch\n",
    "\n",
    "        #getting device type\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        #training\n",
    "        images_tensor = torch.tensor(x_train, dtype=torch.float32, device=device)\n",
    "        images_tensor = images_tensor.unsqueeze(1)\n",
    "        labels_tensor = torch.tensor(y_train, dtype=torch.long, device=device)\n",
    "\n",
    "        # validation\n",
    "        images_valid_tensor = torch.tensor(x_valid, dtype=torch.float32, device=device)\n",
    "        images_valid_tensor = images_valid_tensor.unsqueeze(1)\n",
    "        labels_valid_tensor = torch.tensor(y_valid, dtype=torch.long, device=device)\n",
    "\n",
    "        # testing\n",
    "        images_testing_tensor = torch.tensor(x_test, dtype=torch.float32, device=device)\n",
    "        images_testing_tensor = images_testing_tensor.unsqueeze(1)\n",
    "        labels_testing_tensor = torch.tensor(y_test, dtype=torch.long, device=device)\n",
    "\n",
    "        batch_size = 2048\n",
    "\n",
    "        # Create a TensorDataset\n",
    "        # training\n",
    "        dataset_train = td.TensorDataset(images_tensor, labels_tensor)\n",
    "        data_loader = td.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "        # validation\n",
    "        dataset_valid = td.TensorDataset(images_valid_tensor, labels_valid_tensor)\n",
    "        valid_loader = td.DataLoader(dataset_valid, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "        # testing\n",
    "        dataset_test = td.TensorDataset(images_testing_tensor, labels_testing_tensor)\n",
    "        test_loader = td.DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "        # # save each dataset\n",
    "        # torch.save(dataset_train, 'dataset_train.pt')\n",
    "        # torch.save(dataset_valid, 'dataset_valid.pt')\n",
    "        # torch.save(dataset_test, 'dataset_test.pt')\n",
    "\n",
    "        #save loaders\n",
    "        torch.save(data_loader, 'kfolds/data_loader_kfold%s.pt'%(i))\n",
    "        torch.save(valid_loader, 'kfolds/valid_loader_kfold%s.pt'%(i))\n",
    "        torch.save(test_loader, 'kfolds/test_loader_kfold%s.pt'%(i))\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters and settings\n",
    "batch_size = 64\n",
    "test_batch_size = 64\n",
    "input_size = 1 # because there is only one channel \n",
    "output_size = 4\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_image(arr_in):\n",
    "    for directory in ['focused', 'happy', 'neutral', 'surprised']:\n",
    "                images = os.listdir(\"../concat_data/%s\" % directory)\n",
    "                #Iterate through the images\n",
    "                for image in images:\n",
    "                    #check extension of the image\n",
    "                    if image.split(\".\")[-1] == \"jpg\":\n",
    "                        #Read the image\n",
    "                        img = cv2.imread(\"../concat_data/%s/%s\" %(directory, image), 0)\n",
    "                        #Flatten the image\n",
    "                        # img = img.flatten()\n",
    "                        #Add the flattened image to the list\n",
    "                        if np.array_equal(img, arr_in):\n",
    "                            # \n",
    "                            print(image)\n",
    "                            print(directory)\n",
    "                            return image, directory\n",
    "                            \n",
    "         \n",
    "    return None\n",
    "def find_respective_images(tensor_in):\n",
    "    # finds the image in the one of the directories\n",
    "    # tensor_in: tensor\n",
    "    # return: string\n",
    "    dict_out = {'focused': [], 'happy': [], 'neutral': [], 'surprised': []}\n",
    "\n",
    "    #Get the list of images in the directory\n",
    "    for element in tensor_in:\n",
    "        for element_name in element:\n",
    "            numpy_tensor = element_name.numpy()\n",
    "            image, directory = find_image(numpy_tensor)\n",
    "            dict_out[directory].append(image)\n",
    "\n",
    "            \n",
    "    \n",
    "    # print(tensor_in.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Create data that can be fed into pytorch\n",
    "\n",
    "#getting device type\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#training\n",
    "images_tensor = torch.tensor(x_train, dtype=torch.float32, device=device)\n",
    "images_tensor = images_tensor.unsqueeze(1)\n",
    "labels_tensor = torch.tensor(y_train, dtype=torch.long, device=device)\n",
    "\n",
    "# validation\n",
    "images_valid_tensor = torch.tensor(x_valid, dtype=torch.float32, device=device)\n",
    "images_valid_tensor = images_valid_tensor.unsqueeze(1)\n",
    "labels_valid_tensor = torch.tensor(y_valid, dtype=torch.long, device=device)\n",
    "\n",
    "# testing\n",
    "images_testing_tensor = torch.tensor(x_test, dtype=torch.float32, device=device)\n",
    "images_testing_tensor = images_testing_tensor.unsqueeze(1)\n",
    "labels_testing_tensor = torch.tensor(y_test, dtype=torch.long, device=device)\n",
    "\n",
    "batch_size = 2048\n",
    "\n",
    "# Create a TensorDataset\n",
    "# training\n",
    "dataset_train = td.TensorDataset(images_tensor, labels_tensor)\n",
    "data_loader = td.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# validation\n",
    "dataset_valid = td.TensorDataset(images_valid_tensor, labels_valid_tensor)\n",
    "valid_loader = td.DataLoader(dataset_valid, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# testing\n",
    "dataset_test = td.TensorDataset(images_testing_tensor, labels_testing_tensor)\n",
    "test_loader = td.DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# # save each dataset\n",
    "# torch.save(dataset_train, 'dataset_train.pt')\n",
    "# torch.save(dataset_valid, 'dataset_valid.pt')\n",
    "# torch.save(dataset_test, 'dataset_test.pt')\n",
    "\n",
    "#save loaders\n",
    "torch.save(data_loader, 'data_loader.pt')\n",
    "torch.save(valid_loader, 'valid_loader.pt')\n",
    "torch.save(test_loader, 'test_loader.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_unique_sets():\n",
    "    for name in x_test_name:\n",
    "        if (name in x_valid_name) or (name in x_train_name):\n",
    "            print(name)\n",
    "            print(\"error\")\n",
    "    for name in x_valid_name:\n",
    "        if (name in x_test_name) or (name in x_train_name):\n",
    "            print(name)\n",
    "            print(\"error\")\n",
    "    for name in x_train_name:\n",
    "        if (name in x_valid_name) or (name in x_test_name):\n",
    "            print(name)\n",
    "            print(\"error\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
