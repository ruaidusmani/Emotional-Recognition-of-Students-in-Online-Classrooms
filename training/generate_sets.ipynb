{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as td\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_open = \"../concat_data_tagged/\"\n",
    "enable_kfold = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Takes images in concat_data and flatten them into a 1D array\n",
    "def flatten_images():\n",
    "    images_dict = {'focused': [],\n",
    "                    'happy': [],\n",
    "                    'neutral': [],\n",
    "                    'surprised': []}\n",
    "    image_name_dict = {'focused': [],\n",
    "                    'happy': [],\n",
    "                    'neutral': [],\n",
    "                    'surprised': []}\n",
    "    \n",
    "    for category in ['focused', 'happy', 'neutral', 'surprised']:\n",
    "        #Get the list of images in the directory\n",
    "        images = os.listdir(path_to_open + \"%s\" % category)\n",
    "        #Create an empty list to store the flattened images\n",
    "        flattened_images = []\n",
    "        #Iterate through the images\n",
    "        \n",
    "        for image in images:\n",
    "            #check extension of the image\n",
    "            if image.split(\".\")[-1] == \"jpg\":\n",
    "                #Read the image\n",
    "                img = cv2.imread(path_to_open + \"%s/%s\" %(category, image), 0)\n",
    "                #Flatten the image\n",
    "                # img = img.flatten()\n",
    "                #Add the flattened image to the list\n",
    "                images_dict[category].append(img)\n",
    "                # image_name_dict[category].append(category + \"_\" + image)\n",
    "                image_name_dict[category].append(image)\n",
    "\n",
    "\n",
    "    #Return the list of flattened images\n",
    "    return images_dict, image_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_image(image_path):\n",
    "    img = cv2.imread(image_path, 0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation functions\n",
    "\n",
    "def flip(image):\n",
    "    return cv2.flip(image, 1) # flipping around y-axis\n",
    "\n",
    "def rotate(image):\n",
    "    angle = np.random.uniform(-5,5)\n",
    "    M = cv2.getRotationMatrix2D((image.shape[1] / 2, image.shape[0] / 2), angle, 1)\n",
    "    return cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "def brighten(image):\n",
    "    grey = False\n",
    "    if len(image.shape) == 2:\n",
    "        grey = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    factor = np.random.uniform(0.5, 1.5)\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hsv[:,:,2] = np.clip(hsv[:,:,2] * factor, 0, 255)\n",
    "    bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR) \n",
    "    return bgr if not grey else cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "def change_contrast(image):\n",
    "    factor = np.random.uniform(0.5, 1.5)\n",
    "    return cv2.convertScaleAbs(image, alpha=factor, beta=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(images, labels):\n",
    "    augmented_images = []\n",
    "    augmented_labels = []\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        image = images[i]\n",
    "        label = labels[i]\n",
    "\n",
    "        # save original image\n",
    "        augmented_images.append(image)\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "        # flipping\n",
    "        augmented_images.append(flip(image))\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "        # rotating\n",
    "        augmented_images.append(rotate(image))\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "        # brightening\n",
    "        augmented_images.append(brighten(image))\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "        # changing contrast\n",
    "        augmented_images.append(change_contrast(image))\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "    return augmented_images, augmented_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['surprised_157_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'neutral_311_chicago-faces_male_adult_white.jpg', 'happy_125_chicago-faces_male_adult_black.jpg', 'happy_22_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', 'happy_13_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', 'neutral_3_chicago-faces_male_adult_white.jpg', 'neutral_87_chicago-faces_female_adult_white.jpg', 'surprised_84_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_young.jpg', 'surprised_191_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', 'surprised_92_face-expression-recognition-dataset-jonathan-oheix_female_black_adult.jpg', 'focused_124_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', 'surprised_117_face-expression-recognition-dataset-jonathan-oheix_female_black_adult.jpg', 'focused_74_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', 'surprised_142_face-expression-recognition-dataset-jonathan-oheix_male_white_young.jpg', 'happy_210_chicago-faces_female_adult_white.jpg', 'focused_180_MMA-FACIAL-EXPRESSION-mahmoud_male_asian_adult.jpg', 'surprised_376_face-expression-recognition-dataset-jonathan-oheix_male_white_young.jpg', 'happy_123_chicago-faces_male_adult_black.jpg', 'neutral_141_chicago-faces_male_adult_white.jpg', 'surprised_509_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'happy_60_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', 'focused_64_MMA-FACIAL-EXPRESSION-mahmoud_male_black_adult.jpg', 'focused_72_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', 'focused_34_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', 'surprised_167_face-expression-recognition-dataset-jonathan-oheix_female_white_young.jpg', 'surprised_235_face-expression-recognition-dataset-jonathan-oheix_male_asian_adult.jpg', 'focused_36_MMA-FACIAL-EXPRESSION-mahmoud_male_asian_adult.jpg', 'focused_101_MMA-FACIAL-EXPRESSION-mahmoud_male_black_adult.jpg', 'surprised_88_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'focused_134_MMA-FACIAL-EXPRESSION-mahmoud_male_white_old.jpg', 'happy_151_chicago-faces_other_gender_adult_black.jpg', 'neutral_240_chicago-faces_male_adult_white.jpg', 'happy_209_chicago-faces_male_adult_white.jpg', 'neutral_103_chicago-faces_female_adult_black.jpg', 'happy_183_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', 'neutral_39_chicago-faces_male_adult_asian.jpg', 'happy_255_chicago-faces_male_adult_black.jpg', 'surprised_432_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_young.jpg', 'happy_53_chicago-faces_male_adult_white.jpg', 'surprised_406_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', 'focused_11_UTK-sanjaya_female_white_adult.jpg', 'happy_80_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', 'happy_47_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', 'focused_16_angry-face-expression-recognition-dataset-jonathan-oheix_female_asian_adult.jpg', 'focused_95_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', 'focused_188_angry-face-expression-recognition-dataset-jonathan-oheix_female_white_young.jpg', 'focused_164_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', 'happy_43_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', 'neutral_153_chicago-faces_female_adult_black.jpg', 'happy_256_chicago-faces_female_adult_black.jpg', 'happy_73_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', 'surprised_504_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', 'neutral_0_chicago-faces_female_adult_asian.jpg', 'focused_17_focused-face-FER-2013-luis-MANAS-SAMBARE_male_white_adult.jpg', 'neutral_480_chicago-faces_female_adult_black.jpg', 'happy_65_chicago-faces_male_adult_black.jpg', 'focused_22_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', 'happy_7_chicago-faces_male_adult_white.jpg', 'surprised_320_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'neutral_21_chicago-faces_male_adult_white.jpg', 'focused_34_angry-face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'surprised_52_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', 'focused_123_MMA-FACIAL-EXPRESSION-mahmoud_female_asian_adult.jpg', 'focused_13_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', 'focused_2_human-facial-expression-dataset_male_white_adult.jpg', 'happy_52_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', 'focused_186_angry-face-expression-recognition-dataset-jonathan-oheix_male_black_adult.jpg', 'surprised_512_face-expression-recognition-dataset-jonathan-oheix_male_white_young.jpg', 'neutral_58_chicago-faces_male_adult_white.jpg', 'surprised_451_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_young.jpg', 'neutral_396_chicago-faces_male_adult_asian.jpg', 'surprised_327_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', 'focused_44_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_old.jpg', 'happy_67_chicago-faces_male_adult_black.jpg', 'happy_60_chicago-faces_female_adult_asian.jpg', 'neutral_438_chicago-faces_male_adult_asian.jpg', 'surprised_414_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', 'neutral_205_chicago-faces_male_adult_asian.jpg', 'surprised_136_face-expression-recognition-dataset-jonathan-oheix_female_white_young.jpg', 'neutral_95_chicago-faces_female_adult_asian.jpg', 'happy_234_chicago-faces_female_adult_white.jpg', 'focused_50_angry-face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'happy_154_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', 'neutral_466_chicago-faces_female_adult_white.jpg', 'happy_164_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', 'focused_120_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_old.jpg', 'focused_104_angry-face-expression-recognition-dataset-jonathan-oheix_male_hispanic_adult.jpg', 'neutral_38_chicago-faces_male_adult_asian.jpg', 'focused_14_UTK-sanjaya_male_black_adult.jpg', 'surprised_48_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'neutral_9_chicago-faces_female_adult_white.jpg', 'happy_142_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_hispanic.jpg', 'neutral_301_chicago-faces_female_adult_white.jpg', 'neutral_424_chicago-faces_female_adult_asian.jpg', 'focused_185_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_old.jpg', 'neutral_187_chicago-faces_female_adult_black.jpg', 'neutral_70_chicago-faces_male_adult_white.jpg', 'focused_122_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', 'focused_90_angry-face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'surprised_107_face-expression-recognition-dataset-jonathan-oheix_female_black_adult.jpg', 'surprised_517_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', 'happy_85_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', 'happy_165_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', 'focused_20_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', 'happy_168_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', 'surprised_94_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'happy_213_chicago-faces_male_adult_black.jpg', 'happy_19_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', 'happy_133_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', 'neutral_372_chicago-faces_female_adult_hispanic.jpg', 'neutral_60_chicago-faces_female_adult_hispanic.jpg', 'surprised_8_face-expression-recognition-dataset-jonathan-oheix_male_white_young.jpg', 'neutral_88_chicago-faces_male_adult_asian.jpg', 'surprised_304_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', 'neutral_237_chicago-faces_female_adult_asian.jpg', 'happy_219_chicago-faces_female_adult_asian.jpg', 'neutral_312_chicago-faces_male_adult_white.jpg', 'surprised_66_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', 'surprised_274_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'happy_106_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', 'focused_175_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', 'happy_92_chicago-faces_male_adult_white.jpg', 'focused_83_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', 'surprised_113_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', 'neutral_202_chicago-faces_female_adult_white.jpg', 'neutral_62_chicago-faces_male_adult_hispanic.jpg', 'neutral_374_chicago-faces_female_adult_white.jpg', 'surprised_251_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'neutral_278_chicago-faces_female_adult_black.jpg', 'neutral_222_chicago-faces_female_adult_black.jpg', 'surprised_147_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'neutral_378_chicago-faces_female_adult_asian.jpg', 'surprised_392_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'focused_3_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', 'focused_56_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', 'surprised_466_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'surprised_68_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'happy_188_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', 'surprised_64_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'surprised_245_face-expression-recognition-dataset-jonathan-oheix_male_white_young.jpg', 'neutral_175_chicago-faces_male_adult_asian.jpg', 'focused_65_MMA-FACIAL-EXPRESSION-mahmoud_female_asian_adult.jpg', 'happy_242_chicago-faces_female_adult_black.jpg', 'neutral_117_chicago-faces_male_adult_asian.jpg', 'happy_23_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', 'surprised_79_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'happy_227_chicago-faces_male_adult_black.jpg', 'surprised_56_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'happy_176_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', 'surprised_502_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'surprised_350_face-expression-recognition-dataset-jonathan-oheix_male_white_young.jpg', 'surprised_38_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', 'focused_35_UTK-sanjaya_female_white_adult.jpg', 'neutral_184_chicago-faces_female_adult_white.jpg', 'neutral_216_chicago-faces_female_adult_asian.jpg', 'surprised_463_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', 'focused_11_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', 'happy_99_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_black.jpg', 'neutral_156_chicago-faces_female_adult_asian.jpg', 'neutral_250_chicago-faces_male_adult_black.jpg', 'neutral_461_chicago-faces_female_adult_black.jpg', 'surprised_355_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_young.jpg', 'neutral_168_chicago-faces_male_adult_black.jpg', 'neutral_180_chicago-faces_male_adult_hispanic.jpg', 'focused_176_angry-face-expression-recognition-dataset-jonathan-oheix_male_black_adult.jpg', 'neutral_228_chicago-faces_female_adult_hispanic.jpg', 'happy_105_chicago-faces_female_adult_black.jpg', 'focused_200_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', 'surprised_431_face-expression-recognition-dataset-jonathan-oheix_other_gender_black_young.jpg', 'happy_42_chicago-faces_male_adult_white.jpg', 'focused_83_MMA-FACIAL-EXPRESSION-mahmoud_male_white_old.jpg', 'surprised_155_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'neutral_130_chicago-faces_male_adult_black.jpg', 'neutral_22_chicago-faces_male_adult_white.jpg', 'surprised_153_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_young.jpg', 'focused_44_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', 'happy_91_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', 'neutral_472_chicago-faces_female_adult_asian.jpg', 'surprised_41_face-expression-recognition-dataset-jonathan-oheix_male_white_young.jpg', 'surprised_199_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'focused_19_focused-face-FER-2013-luis-MANAS-SAMBARE_male_white_old.jpg', 'happy_257_chicago-faces_male_adult_white.jpg', 'neutral_78_chicago-faces_female_adult_black.jpg', 'happy_94_chicago-faces_male_adult_white.jpg', 'neutral_389_chicago-faces_female_adult_white.jpg', 'focused_31_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', 'neutral_399_chicago-faces_female_adult_white.jpg', 'happy_150_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', 'focused_21_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', 'neutral_417_chicago-faces_male_adult_black.jpg', 'neutral_490_chicago-faces_female_adult_white.jpg', 'happy_215_chicago-faces_female_adult_white.jpg', 'neutral_248_chicago-faces_female_adult_asian.jpg', 'focused_3_UTK-sanjaya_male_white_adult.jpg', 'happy_83_chicago-faces_female_adult_hispanic.jpg', 'happy_302_chicago-faces_female_adult_white.jpg', 'surprised_452_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'neutral_260_chicago-faces_male_adult_white.jpg', 'surprised_101_face-expression-recognition-dataset-jonathan-oheix_female_black_adult.jpg', 'happy_58_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', 'happy_252_chicago-faces_female_adult_white.jpg', 'surprised_213_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'neutral_447_chicago-faces_female_adult_black.jpg', 'neutral_342_chicago-faces_female_adult_hispanic.jpg', 'focused_11_focused-face-FER-2013-luis-MANAS-SAMBARE_female_asian_adult.jpg', 'neutral_227_chicago-faces_female_adult_white.jpg', 'focused_15_human-facial-expression-dataset_male_white_adult.jpg', 'happy_178_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', 'focused_7_human-facial-expression-dataset_female_asian_adult.jpg', 'focused_196_angry-face-expression-recognition-dataset-jonathan-oheix_male_other_race_adult.jpg', 'happy_132_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', 'neutral_413_chicago-faces_female_adult_hispanic.jpg', 'focused_115_MMA-FACIAL-EXPRESSION-mahmoud_male_white_old.jpg', 'surprised_323_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'focused_111_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', 'surprised_301_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'surprised_103_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'focused_0_UTK-sanjaya_female_white_adult.jpg', 'happy_137_kaggle__zawarkhan69__human-facial-expression-dataset_female_adult_white.jpg', 'neutral_33_chicago-faces_female_adult_hispanic.jpg', 'surprised_344_face-expression-recognition-dataset-jonathan-oheix_female_black_adult.jpg', 'surprised_19_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', 'happy_29_chicago-faces_female_adult_white.jpg', 'happy_142_chicago-faces_female_adult_white.jpg', 'happy_48_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', 'surprised_156_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_adult.jpg', 'neutral_112_chicago-faces_male_adult_black.jpg', 'surprised_210_face-expression-recognition-dataset-jonathan-oheix_female_black_adult.jpg', 'focused_78_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', 'focused_10_human-facial-expression-dataset_male_white_adult.jpg', 'surprised_499_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'surprised_287_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'neutral_133_chicago-faces_male_adult_white.jpg', 'surprised_197_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'surprised_491_face-expression-recognition-dataset-jonathan-oheix_male_black_adult.jpg', 'happy_23_chicago-faces_female_adult_black.jpg', 'surprised_78_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'focused_19_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', 'focused_32_MMA-FACIAL-EXPRESSION-mahmoud_female_white_adult.jpg', 'focused_125_angry-face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'happy_51_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', 'focused_26_angry-face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'focused_52_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', 'happy_251_chicago-faces_female_adult_black.jpg', 'surprised_276_face-expression-recognition-dataset-jonathan-oheix_female_white_old.jpg', 'neutral_448_chicago-faces_male_adult_asian.jpg', 'focused_11_MMA-FACIAL-EXPRESSION-mahmoud_male_black_adult.jpg', 'happy_62_chicago-faces_female_adult_white.jpg', 'neutral_465_chicago-faces_female_adult_white.jpg', 'happy_147_chicago-faces_female_adult_white.jpg', 'neutral_467_chicago-faces_male_adult_black.jpg', 'focused_6_UTK-sanjaya_male_white_adult.jpg', 'focused_1_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', 'surprised_481_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', 'neutral_224_chicago-faces_male_adult_asian.jpg', 'surprised_447_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'neutral_443_chicago-faces_male_adult_asian.jpg', 'happy_145_chicago-faces_female_adult_asian.jpg', 'focused_57_angry-face-expression-recognition-dataset-jonathan-oheix_male_other_race_old.jpg', 'happy_129_chicago-faces_female_adult_white.jpg', 'happy_117_chicago-faces_female_adult_black.jpg', 'focused_45_UTK-sanjaya_male_other_race_adult.jpg', 'focused_210_angry-face-expression-recognition-dataset-jonathan-oheix_female_white_old.jpg', 'happy_2_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', 'happy_115_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', 'focused_60_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_old.jpg', 'neutral_388_chicago-faces_male_adult_asian.jpg', 'neutral_244_chicago-faces_female_adult_hispanic.jpg', 'surprised_76_face-expression-recognition-dataset-jonathan-oheix_female_black_adult.jpg', 'happy_144_chicago-faces_female_adult_white.jpg', 'neutral_221_chicago-faces_female_adult_asian.jpg', 'focused_174_angry-face-expression-recognition-dataset-jonathan-oheix_male_asian_old.jpg', 'neutral_291_chicago-faces_male_adult_white.jpg', 'neutral_177_chicago-faces_male_adult_white.jpg', 'focused_23_UTK-sanjaya_male_white_adult.jpg', 'happy_17_chicago-faces_female_adult_black.jpg', 'happy_127_kaggle__zawarkhan69__human-facial-expression-dataset_female_old_white.jpg', 'happy_118_kaggle__zawarkhan69__human-facial-expression-dataset_male_adult_white.jpg', 'surprised_182_face-expression-recognition-dataset-jonathan-oheix_female_white_young.jpg', 'focused_163_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', 'neutral_255_chicago-faces_female_adult_hispanic.jpg', 'focused_20_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', 'neutral_99_chicago-faces_female_adult_white.jpg', 'focused_23_angry-face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', 'surprised_518_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'focused_60_UTK-sanjaya_male_white_adult.jpg', 'focused_17_human-facial-expression-dataset_female_white_adult.jpg', 'surprised_330_face-expression-recognition-dataset-jonathan-oheix_female_black_adult.jpg', 'surprised_90_face-expression-recognition-dataset-jonathan-oheix_female_white_adult.jpg', 'happy_97_chicago-faces_female_adult_black.jpg', 'neutral_290_chicago-faces_male_adult_white.jpg', 'happy_181_chicago-faces_female_adult_white.jpg', 'focused_13_MMA-FACIAL-EXPRESSION-mahmoud_male_white_adult.jpg', 'happy_206_chicago-faces_other_gender_adult_black.jpg', 'focused_3_focused-face-FER-2013-luis-MANAS-SAMBARE_male_white_adult.jpg', 'neutral_364_chicago-faces_male_adult_asian.jpg', 'surprised_61_face-expression-recognition-dataset-jonathan-oheix_male_white_adult.jpg', 'happy_71_chicago-faces_female_adult_black.jpg', 'surprised_357_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_young.jpg', 'surprised_456_face-expression-recognition-dataset-jonathan-oheix_other_gender_white_young.jpg']\n"
     ]
    }
   ],
   "source": [
    "# add images of each category into an array\n",
    "\n",
    "\n",
    "images_dict, image_name_dict = flatten_images() \n",
    "\n",
    "# tokensize labels\n",
    "labels = {'focused': 0,\n",
    "          'happy': 1,\n",
    "          'neutral': 2,\n",
    "          'surprised': 3}\n",
    "\n",
    "\n",
    "# concatencate all the data with respective labels\n",
    "x = []\n",
    "y = []\n",
    "for key in images_dict:\n",
    "    for image in images_dict[key]:\n",
    "        x.append(image)\n",
    "        y.append(labels[key])\n",
    "x_name = []\n",
    "y_name = []\n",
    "for key in image_name_dict:\n",
    "    for image_name in image_name_dict[key]:\n",
    "        x_name.append(image_name)\n",
    "        y_name.append(labels[key])\n",
    "\n",
    "\n",
    "# split into training and valid/testing\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(x, y, test_size =0.30, random_state=42, stratify=y)\n",
    "x_train_name, x_temp_name, y_train_name, y_temp_name = train_test_split(x_name, y_name, test_size =0.30, random_state=42, stratify=y_name)\n",
    "\n",
    "# split x_temp and y_temp into validation and testing\\\n",
    "x_valid, x_test, y_valid, y_test = train_test_split(x_temp, y_temp, test_size =0.50, random_state=42, stratify=y_temp)\n",
    "x_valid_name, x_test_name, y_valid_name, y_test_name = train_test_split(x_temp_name, y_temp_name, test_size =0.50, random_state=42, stratify=y_temp_name)\n",
    "\n",
    "print(x_test_name)\n",
    "# add all elements of x_test_name into a .txt file\n",
    "with open('test_set_images_categories.txt', 'w') as f:\n",
    "    for item in x_test_name:\n",
    "        f.write(\"%s,\" % item)\n",
    "\n",
    "# augment the data\n",
    "x_train, y_train = augment(x_train, y_train)\n",
    "x_valid, y_valid = augment(x_valid, y_valid)\n",
    "x_test, y_test = augment(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "[  0  52 107 163 216 274 330 388 441 496]\n",
      "--------------------------------\n",
      "[  0  55 112 166 226 279 337 393 451 508]\n",
      "--------------------------------\n",
      "[  0  54 108 160 216 276 330 387 448 503]\n",
      "--------------------------------\n",
      "[  0  55 110 164 220 273 333 391 446 503]\n",
      "--------------------------------\n",
      "[  0  54 107 169 226 278 339 393 448 500]\n",
      "--------------------------------\n",
      "[  1  63 129 184 243 297 352 407 462 514]\n",
      "--------------------------------\n",
      "[  0  54 112 165 219 273 324 379 434 490]\n",
      "--------------------------------\n",
      "[  0  59 110 168 221 275 330 384 438 494]\n",
      "--------------------------------\n",
      "[  0  55 106 164 218 274 328 379 433 490]\n",
      "--------------------------------\n",
      "[  0  56 111 165 223 278 332 388 444 500]\n"
     ]
    }
   ],
   "source": [
    "if (enable_kfold):\n",
    "    # use k-fold cross validation to split the data\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    i = 1\n",
    "    for train_index, test_index in kf.split(x):\n",
    "\n",
    "        # print(f\"Fold {i}:\")\n",
    "        # print(f\"  Train: index={train_index}\")\n",
    "        # split into training and valid/testing\n",
    "\n",
    "        #convert x and y to numpy arrays\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "        x_name = np.array(x_name)\n",
    "        y_name = np.array(y_name)\n",
    "\n",
    "\n",
    "        #select the indices for the training and testing data\n",
    "        x_train, x_temp  = x[train_index], x[test_index]\n",
    "        y_train, y_temp  = y[train_index], y[test_index]\n",
    "        x_train_name, x_temp_name  = x_name[train_index], x_name[test_index]\n",
    "        y_train_name, y_temp_name  = y_name[train_index], y_name[test_index]\n",
    "\n",
    "        \n",
    "        #print first 10 elements of x_train\n",
    "        print(\"--------------------------------\")\n",
    "        print(train_index[[0,50,100,150,200,250,300,350,400,450]])\n",
    "\n",
    "        # split x_temp and y_temp into validation and testing\\\n",
    "        x_valid, x_test, y_valid, y_test = train_test_split(x_temp, y_temp, test_size =0.50, random_state=42, stratify=y_temp)\n",
    "        x_valid_name, x_test_name, y_valid_name, y_test_name = train_test_split(x_temp_name, y_temp_name, test_size =0.50, random_state=42, stratify=y_temp_name)\n",
    "\n",
    "\n",
    "        # augment the data\n",
    "        x_train, y_train = augment(x_train, y_train)\n",
    "        x_valid, y_valid = augment(x_valid, y_valid)\n",
    "        x_test, y_test = augment(x_test, y_test)\n",
    "\n",
    "\n",
    "        #Create data that can be fed into pytorch\n",
    "\n",
    "        #getting device type\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        #training\n",
    "        images_tensor = torch.tensor(x_train, dtype=torch.float32, device=device)\n",
    "        images_tensor = images_tensor.unsqueeze(1)\n",
    "        labels_tensor = torch.tensor(y_train, dtype=torch.long, device=device)\n",
    "\n",
    "        # validation\n",
    "        images_valid_tensor = torch.tensor(x_valid, dtype=torch.float32, device=device)\n",
    "        images_valid_tensor = images_valid_tensor.unsqueeze(1)\n",
    "        labels_valid_tensor = torch.tensor(y_valid, dtype=torch.long, device=device)\n",
    "\n",
    "        # testing\n",
    "        images_testing_tensor = torch.tensor(x_test, dtype=torch.float32, device=device)\n",
    "        images_testing_tensor = images_testing_tensor.unsqueeze(1)\n",
    "        labels_testing_tensor = torch.tensor(y_test, dtype=torch.long, device=device)\n",
    "\n",
    "        batch_size = 2048\n",
    "\n",
    "        # Create a TensorDataset\n",
    "        # training\n",
    "        dataset_train = td.TensorDataset(images_tensor, labels_tensor)\n",
    "        data_loader = td.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "        # validation\n",
    "        dataset_valid = td.TensorDataset(images_valid_tensor, labels_valid_tensor)\n",
    "        valid_loader = td.DataLoader(dataset_valid, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "        # testing\n",
    "        dataset_test = td.TensorDataset(images_testing_tensor, labels_testing_tensor)\n",
    "        test_loader = td.DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "        # # save each dataset\n",
    "        # torch.save(dataset_train, 'dataset_train.pt')\n",
    "        # torch.save(dataset_valid, 'dataset_valid.pt')\n",
    "        # torch.save(dataset_test, 'dataset_test.pt')\n",
    "\n",
    "        #save loaders\n",
    "        torch.save(data_loader, 'kfolds/data_loader_kfold%s.pt'%(i))\n",
    "        torch.save(valid_loader, 'kfolds/valid_loader_kfold%s.pt'%(i))\n",
    "        torch.save(test_loader, 'kfolds/test_loader_kfold%s.pt'%(i))\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters and settings\n",
    "batch_size = 64\n",
    "test_batch_size = 64\n",
    "input_size = 1 # because there is only one channel \n",
    "output_size = 4\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_image(arr_in):\n",
    "    for directory in ['focused', 'happy', 'neutral', 'surprised']:\n",
    "                images = os.listdir(\"../concat_data/%s\" % directory)\n",
    "                #Iterate through the images\n",
    "                for image in images:\n",
    "                    #check extension of the image\n",
    "                    if image.split(\".\")[-1] == \"jpg\":\n",
    "                        #Read the image\n",
    "                        img = cv2.imread(\"../concat_data/%s/%s\" %(directory, image), 0)\n",
    "                        #Flatten the image\n",
    "                        # img = img.flatten()\n",
    "                        #Add the flattened image to the list\n",
    "                        if np.array_equal(img, arr_in):\n",
    "                            # \n",
    "                            print(image)\n",
    "                            print(directory)\n",
    "                            return image, directory\n",
    "                            \n",
    "         \n",
    "    return None\n",
    "def find_respective_images(tensor_in):\n",
    "    # finds the image in the one of the directories\n",
    "    # tensor_in: tensor\n",
    "    # return: string\n",
    "    dict_out = {'focused': [], 'happy': [], 'neutral': [], 'surprised': []}\n",
    "\n",
    "    #Get the list of images in the directory\n",
    "    for element in tensor_in:\n",
    "        for element_name in element:\n",
    "            numpy_tensor = element_name.numpy()\n",
    "            image, directory = find_image(numpy_tensor)\n",
    "            dict_out[directory].append(image)\n",
    "\n",
    "            \n",
    "    \n",
    "    # print(tensor_in.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Create data that can be fed into pytorch\n",
    "\n",
    "#getting device type\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#training\n",
    "images_tensor = torch.tensor(x_train, dtype=torch.float32, device=device)\n",
    "images_tensor = images_tensor.unsqueeze(1)\n",
    "labels_tensor = torch.tensor(y_train, dtype=torch.long, device=device)\n",
    "\n",
    "# validation\n",
    "images_valid_tensor = torch.tensor(x_valid, dtype=torch.float32, device=device)\n",
    "images_valid_tensor = images_valid_tensor.unsqueeze(1)\n",
    "labels_valid_tensor = torch.tensor(y_valid, dtype=torch.long, device=device)\n",
    "\n",
    "# testing\n",
    "images_testing_tensor = torch.tensor(x_test, dtype=torch.float32, device=device)\n",
    "images_testing_tensor = images_testing_tensor.unsqueeze(1)\n",
    "labels_testing_tensor = torch.tensor(y_test, dtype=torch.long, device=device)\n",
    "\n",
    "batch_size = 2048\n",
    "\n",
    "# Create a TensorDataset\n",
    "# training\n",
    "dataset_train = td.TensorDataset(images_tensor, labels_tensor)\n",
    "data_loader = td.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# validation\n",
    "dataset_valid = td.TensorDataset(images_valid_tensor, labels_valid_tensor)\n",
    "valid_loader = td.DataLoader(dataset_valid, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# testing\n",
    "dataset_test = td.TensorDataset(images_testing_tensor, labels_testing_tensor)\n",
    "test_loader = td.DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# # save each dataset\n",
    "# torch.save(dataset_train, 'dataset_train.pt')\n",
    "# torch.save(dataset_valid, 'dataset_valid.pt')\n",
    "# torch.save(dataset_test, 'dataset_test.pt')\n",
    "\n",
    "#save loaders\n",
    "torch.save(data_loader, 'data_loader.pt')\n",
    "torch.save(valid_loader, 'valid_loader.pt')\n",
    "torch.save(test_loader, 'test_loader.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_unique_sets():\n",
    "    for name in x_test_name:\n",
    "        if (name in x_valid_name) or (name in x_train_name):\n",
    "            print(name)\n",
    "            print(\"error\")\n",
    "    for name in x_valid_name:\n",
    "        if (name in x_test_name) or (name in x_train_name):\n",
    "            print(name)\n",
    "            print(\"error\")\n",
    "    for name in x_train_name:\n",
    "        if (name in x_valid_name) or (name in x_test_name):\n",
    "            print(name)\n",
    "            print(\"error\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
