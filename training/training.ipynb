{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as td\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trains_kfolds = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters and settings\n",
    "batch_size = 64\n",
    "test_batch_size = 64\n",
    "input_size = 1 # because there is only one channel \n",
    "output_size = 4\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.001\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load traiing, validation and training data\n",
    "\n",
    "data_loader = torch.load('data_loader.pt')\n",
    "valid_loader = torch.load('valid_loader.pt')\n",
    "test_loader = torch.load('test_loader.pt')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Move the data loaders to the desired device\n",
    "data_loader.dataset.tensors = tuple(tensor.to(device) for tensor in data_loader.dataset.tensors)\n",
    "valid_loader.dataset.tensors = tuple(tensor.to(device) for tensor in valid_loader.dataset.tensors)\n",
    "test_loader.dataset.tensors = tuple(tensor.to(device) for tensor in test_loader.dataset.tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.name = \"CNN\"\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(12 * 12 * 64, 1000),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1000, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(512, 4)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        # conv layers\n",
    "        x = self.conv_layer(x)\n",
    "        # print(x.shape)\n",
    "        # flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # print(x.shape)\n",
    "        # fc layer\n",
    "        x = self.fc_layer(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN2, self).__init__()\n",
    "        self.name = \"CNN2\"\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=5, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            #get dimensions of last layer\n",
    "            \n",
    "        )\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(64*9*9, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(512, 4)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        # conv layers\n",
    "        x = self.conv_layer(x)\n",
    "        # print(x.shape)\n",
    "        # flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # print(x.shape)\n",
    "        # fc layer\n",
    "        x = self.fc_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN3, self).__init__()\n",
    "        self.name = \"CNN3\"\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=7, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=7, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=7, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),           \n",
    "        )\n",
    "        \n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(7 * 7 * 64, 1000),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(1000, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(512, 4)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, y=None):\n",
    "        # conv layers\n",
    "        x = self.conv_layer(x)\n",
    "        # print(x.shape)\n",
    "        # flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # print(x.shape)\n",
    "        # fc layer\n",
    "        x = self.fc_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_model(model, data_loader, valid_loader, device, save_as_name = ''):\n",
    "    if (save_as_name == '') :\n",
    "        save_as_name = model.name\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    total_step = len(data_loader)\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    f1_list = []\n",
    "\n",
    "    loss_list_test = []\n",
    "    acc_list_test = []\n",
    "    f1_list_test = []\n",
    "\n",
    "    # early stopping parameters\n",
    "    best_loss = 100\n",
    "    patience = 10 # number of epochs to wait before stopping\n",
    "    count = 0\n",
    "    best_epoch = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(data_loader):\n",
    "\n",
    "            # Move images and labels to the device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss_list.append(loss.item())\n",
    "            # Backprop and optimisation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Train accuracy\n",
    "            total = labels.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            acc_list.append(correct / total)\n",
    "            # Train F1 score\n",
    "            f1 = f1_score(labels.cpu().numpy(), predicted.cpu().numpy(), average='macro')\n",
    "            f1_list.append(f1)\n",
    "            # print(i)\n",
    "            # if (i + 1) % 10 == 0:\n",
    "            #     print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "            #     .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "            #     (correct / total) * 100))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (images_test, labels_test) in enumerate(valid_loader):\n",
    "                images_test = images_test.to(device)\n",
    "                labels_test = labels_test.to(device)\n",
    "                outputs_test = model(images_test)\n",
    "                loss_test = criterion(outputs_test, labels_test)\n",
    "                loss_list_test.append(loss_test.item())\n",
    "                total_test = labels_test.size(0)\n",
    "                _, predicted_test = torch.max(outputs_test.data, 1)\n",
    "                correct_test = (predicted_test == labels_test).sum().item()\n",
    "                acc_list_test.append(correct_test / total_test)\n",
    "\n",
    "                #Test F1 score\n",
    "                f1_test = f1_score(labels_test.cpu().numpy(), predicted_test.cpu().numpy(), average='macro')\n",
    "                f1_list_test.append(f1_test)\n",
    "        print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%, F1 Score: {:.2f}'\n",
    "        .format(epoch + 1, num_epochs, i + 1, total_step, loss_test.item(),\n",
    "        (correct / total) * 100, f1_test))\n",
    "\n",
    "\n",
    "        #================= Early stopping =================\n",
    "        \n",
    "        #---------- Early stopping with avg F1 score-------\n",
    "        # early stopping to prevent overfitting\n",
    "        # saving model with best accuracy\n",
    "        # avg_f1 = sum(f1_list_test)/len(f1_list_test)\n",
    "        # print('Average F1 score: ', avg_f1)\n",
    "        # if avg_f1 > best_f1:\n",
    "        #     best_f1 = avg_f1\n",
    "        #     count = 0 # reset count\n",
    "        #     #saving best model thus far\n",
    "        #     torch.save(model.state_dict(), '%s.pth'%(model.name))\n",
    "        # else:\n",
    "        #     count += 1\n",
    "        #     if count == patience:\n",
    "        #         print('Early stopping at epoch %d'%(epoch))\n",
    "        #         break\n",
    "\n",
    "        #------------- Early stopping with loss------------\n",
    "        if loss_test.item() < best_loss:\n",
    "            best_loss = loss_test.item()\n",
    "            count = 0 # reset count\n",
    "            best_epoch = epoch\n",
    "            #saving best model thus far\n",
    "            torch.save(model.state_dict(), '%s.pth'%(save_as_name))\n",
    "            if best_loss < 0.0001:\n",
    "                print('\\n----------------------------------------\\nEarly stopping at epoch %d'%(epoch))\n",
    "                print('Best epoch: ', best_epoch)\n",
    "                print('Best loss: ', best_loss, ' Best test F1 score: ', f1_test, ' Best test accuracy: ', acc_list_test[-1])\n",
    "                break\n",
    "        else:\n",
    "            count += 1\n",
    "            if count == patience:\n",
    "                print('\\n----------------------------------------\\nEarly stopping at epoch %d'%(epoch))\n",
    "                print('Best epoch: ', best_epoch)\n",
    "                print('Best loss: ', best_loss, ' Best test F1 score: ', f1_test, ' Best test accuracy: ', acc_list_test[-1])\n",
    "                break\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for model CNN kfolds:  1\n",
      "Epoch [1/1000], Step [1/5], Loss: 1.7096, Accuracy: 30.07%, F1 Score: 0.26\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m         data_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkfolds/data_loader_kfold\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39m(i))\n\u001b[0;32m      7\u001b[0m         valid_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkfolds/valid_loader_kfold\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39m(i))\n\u001b[1;32m----> 8\u001b[0m         \u001b[43mtrain_and_save_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrained_k_folds/CNN_kfold_\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     10\u001b[0m     train_and_save_model(model1, data_loader, valid_loader, device)\n",
      "Cell \u001b[1;32mIn[19], line 28\u001b[0m, in \u001b[0;36mtrain_and_save_model\u001b[1;34m(model, data_loader, valid_loader, device, save_as_name)\u001b[0m\n\u001b[0;32m     26\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     30\u001b[0m loss_list\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[16], line 32\u001b[0m, in \u001b[0;36mCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m# conv layers\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# flatten\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\activation.py:774\u001b[0m, in \u001b[0;36mLeakyReLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 774\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleaky_relu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnegative_slope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\functional.py:1646\u001b[0m, in \u001b[0;36mleaky_relu\u001b[1;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[0;32m   1644\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(leaky_relu, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, negative_slope\u001b[38;5;241m=\u001b[39mnegative_slope, inplace\u001b[38;5;241m=\u001b[39minplace)\n\u001b[0;32m   1645\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m-> 1646\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleaky_relu_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegative_slope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1647\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1648\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mleaky_relu(\u001b[38;5;28minput\u001b[39m, negative_slope)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model1 = CNN().to(device)\n",
    "if (trains_kfolds):\n",
    "    model = model1\n",
    "    for i in range(1, 11):\n",
    "        print(\"Training for model %s\"%(model.name), \"kfolds: \", i)\n",
    "        data_loader = torch.load('kfolds/data_loader_kfold%s.pt'%(i))\n",
    "        valid_loader = torch.load('kfolds/valid_loader_kfold%s.pt'%(i))\n",
    "        train_and_save_model(model, data_loader, valid_loader, device, 'trained_k_folds/CNN_kfold_%s_%s'%(model.name, i))\n",
    "else:\n",
    "    train_and_save_model(model1, data_loader, valid_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for model CNN2 kfolds:  1\n",
      "Epoch [1/1000], Step [1/5], Loss: 0.7792, Accuracy: 63.12%, F1 Score: 0.73\n",
      "Epoch [2/1000], Step [1/5], Loss: 0.4838, Accuracy: 81.81%, F1 Score: 0.83\n",
      "Epoch [3/1000], Step [1/5], Loss: 0.3605, Accuracy: 88.99%, F1 Score: 0.85\n",
      "Epoch [4/1000], Step [1/5], Loss: 0.2983, Accuracy: 91.96%, F1 Score: 0.88\n",
      "Epoch [5/1000], Step [1/5], Loss: 0.2583, Accuracy: 92.70%, F1 Score: 0.88\n",
      "Epoch [6/1000], Step [1/5], Loss: 0.3112, Accuracy: 95.42%, F1 Score: 0.87\n",
      "Epoch [7/1000], Step [1/5], Loss: 0.2714, Accuracy: 95.17%, F1 Score: 0.89\n",
      "Epoch [8/1000], Step [1/5], Loss: 0.2967, Accuracy: 97.77%, F1 Score: 0.87\n",
      "Epoch [9/1000], Step [1/5], Loss: 0.2396, Accuracy: 97.15%, F1 Score: 0.89\n",
      "Epoch [10/1000], Step [1/5], Loss: 0.2449, Accuracy: 98.76%, F1 Score: 0.90\n",
      "Epoch [11/1000], Step [1/5], Loss: 0.3431, Accuracy: 98.64%, F1 Score: 0.88\n",
      "Epoch [12/1000], Step [1/5], Loss: 0.2831, Accuracy: 99.38%, F1 Score: 0.90\n",
      "Epoch [13/1000], Step [1/5], Loss: 0.2844, Accuracy: 100.00%, F1 Score: 0.89\n",
      "Epoch [14/1000], Step [1/5], Loss: 0.2750, Accuracy: 99.63%, F1 Score: 0.91\n",
      "Epoch [15/1000], Step [1/5], Loss: 0.2749, Accuracy: 99.88%, F1 Score: 0.90\n",
      "Epoch [16/1000], Step [1/5], Loss: 0.2569, Accuracy: 100.00%, F1 Score: 0.91\n",
      "Epoch [17/1000], Step [1/5], Loss: 0.3301, Accuracy: 100.00%, F1 Score: 0.89\n",
      "Epoch [18/1000], Step [1/5], Loss: 0.2758, Accuracy: 100.00%, F1 Score: 0.92\n",
      "Epoch [19/1000], Step [1/5], Loss: 0.3113, Accuracy: 100.00%, F1 Score: 0.91\n",
      "\n",
      "----------------------------------------\n",
      "Early stopping at epoch 18\n",
      "Best epoch:  8\n",
      "Best loss:  0.2395773082971573  Best test F1 score:  0.9050751583465202  Best test accuracy:  0.904\n",
      "Training for model CNN2 kfolds:  2\n",
      "Epoch [1/1000], Step [1/5], Loss: 0.8791, Accuracy: 61.01%, F1 Score: 0.68\n",
      "Epoch [2/1000], Step [1/5], Loss: 0.3709, Accuracy: 80.82%, F1 Score: 0.86\n",
      "Epoch [3/1000], Step [1/5], Loss: 0.2781, Accuracy: 88.00%, F1 Score: 0.91\n",
      "Epoch [4/1000], Step [1/5], Loss: 0.2311, Accuracy: 90.84%, F1 Score: 0.92\n",
      "Epoch [5/1000], Step [1/5], Loss: 0.2311, Accuracy: 92.95%, F1 Score: 0.93\n",
      "Epoch [6/1000], Step [1/5], Loss: 0.2405, Accuracy: 92.33%, F1 Score: 0.93\n",
      "Epoch [7/1000], Step [1/5], Loss: 0.2158, Accuracy: 95.30%, F1 Score: 0.94\n",
      "Epoch [8/1000], Step [1/5], Loss: 0.1963, Accuracy: 95.42%, F1 Score: 0.95\n",
      "Epoch [9/1000], Step [1/5], Loss: 0.2047, Accuracy: 97.77%, F1 Score: 0.94\n",
      "Epoch [10/1000], Step [1/5], Loss: 0.2210, Accuracy: 98.51%, F1 Score: 0.95\n",
      "Epoch [11/1000], Step [1/5], Loss: 0.2511, Accuracy: 98.51%, F1 Score: 0.95\n",
      "Epoch [12/1000], Step [1/5], Loss: 0.2548, Accuracy: 97.90%, F1 Score: 0.93\n",
      "Epoch [13/1000], Step [1/5], Loss: 0.2543, Accuracy: 99.38%, F1 Score: 0.95\n",
      "Epoch [14/1000], Step [1/5], Loss: 0.2915, Accuracy: 99.50%, F1 Score: 0.94\n",
      "Epoch [15/1000], Step [1/5], Loss: 0.3310, Accuracy: 99.13%, F1 Score: 0.94\n",
      "Epoch [16/1000], Step [1/5], Loss: 0.3246, Accuracy: 99.75%, F1 Score: 0.95\n",
      "Epoch [17/1000], Step [1/5], Loss: 0.3436, Accuracy: 100.00%, F1 Score: 0.94\n",
      "Epoch [18/1000], Step [1/5], Loss: 0.3360, Accuracy: 99.88%, F1 Score: 0.94\n",
      "\n",
      "----------------------------------------\n",
      "Early stopping at epoch 17\n",
      "Best epoch:  7\n",
      "Best loss:  0.1963041126728058  Best test F1 score:  0.942192810420881  Best test accuracy:  0.934\n",
      "Training for model CNN2 kfolds:  3\n",
      "Epoch [1/1000], Step [1/5], Loss: 0.8924, Accuracy: 53.34%, F1 Score: 0.68\n",
      "Epoch [2/1000], Step [1/5], Loss: 0.4774, Accuracy: 79.46%, F1 Score: 0.80\n",
      "Epoch [3/1000], Step [1/5], Loss: 0.3818, Accuracy: 89.85%, F1 Score: 0.87\n",
      "Epoch [4/1000], Step [1/5], Loss: 0.2908, Accuracy: 91.83%, F1 Score: 0.89\n",
      "Epoch [5/1000], Step [1/5], Loss: 0.3082, Accuracy: 92.95%, F1 Score: 0.90\n",
      "Epoch [6/1000], Step [1/5], Loss: 0.2771, Accuracy: 94.43%, F1 Score: 0.89\n",
      "Epoch [7/1000], Step [1/5], Loss: 0.3072, Accuracy: 95.54%, F1 Score: 0.91\n",
      "Epoch [8/1000], Step [1/5], Loss: 0.2912, Accuracy: 94.80%, F1 Score: 0.90\n",
      "Epoch [9/1000], Step [1/5], Loss: 0.2559, Accuracy: 96.16%, F1 Score: 0.92\n",
      "Epoch [10/1000], Step [1/5], Loss: 0.2523, Accuracy: 98.76%, F1 Score: 0.92\n",
      "Epoch [11/1000], Step [1/5], Loss: 0.2671, Accuracy: 99.13%, F1 Score: 0.92\n",
      "Epoch [12/1000], Step [1/5], Loss: 0.2407, Accuracy: 99.38%, F1 Score: 0.94\n",
      "Epoch [13/1000], Step [1/5], Loss: 0.2538, Accuracy: 99.63%, F1 Score: 0.93\n",
      "Epoch [14/1000], Step [1/5], Loss: 0.2839, Accuracy: 99.01%, F1 Score: 0.93\n",
      "Epoch [15/1000], Step [1/5], Loss: 0.2710, Accuracy: 99.75%, F1 Score: 0.93\n",
      "Epoch [16/1000], Step [1/5], Loss: 0.3355, Accuracy: 99.63%, F1 Score: 0.91\n",
      "Epoch [17/1000], Step [1/5], Loss: 0.2780, Accuracy: 100.00%, F1 Score: 0.93\n",
      "Epoch [18/1000], Step [1/5], Loss: 0.2961, Accuracy: 99.88%, F1 Score: 0.93\n",
      "Epoch [19/1000], Step [1/5], Loss: 0.3155, Accuracy: 100.00%, F1 Score: 0.94\n",
      "Epoch [20/1000], Step [1/5], Loss: 0.2743, Accuracy: 100.00%, F1 Score: 0.93\n",
      "Epoch [21/1000], Step [1/5], Loss: 0.2790, Accuracy: 100.00%, F1 Score: 0.93\n",
      "Epoch [22/1000], Step [1/5], Loss: 0.2657, Accuracy: 100.00%, F1 Score: 0.94\n",
      "\n",
      "----------------------------------------\n",
      "Early stopping at epoch 21\n",
      "Best epoch:  11\n",
      "Best loss:  0.24070130288600922  Best test F1 score:  0.9372167814984372  Best test accuracy:  0.938\n",
      "Training for model CNN2 kfolds:  4\n",
      "Epoch [1/1000], Step [1/5], Loss: 0.8158, Accuracy: 59.90%, F1 Score: 0.71\n",
      "Epoch [2/1000], Step [1/5], Loss: 0.4694, Accuracy: 80.57%, F1 Score: 0.82\n",
      "Epoch [3/1000], Step [1/5], Loss: 0.3309, Accuracy: 91.09%, F1 Score: 0.87\n",
      "Epoch [4/1000], Step [1/5], Loss: 0.3339, Accuracy: 92.95%, F1 Score: 0.88\n",
      "Epoch [5/1000], Step [1/5], Loss: 0.2594, Accuracy: 93.94%, F1 Score: 0.92\n",
      "Epoch [6/1000], Step [1/5], Loss: 0.1860, Accuracy: 95.30%, F1 Score: 0.92\n",
      "Epoch [7/1000], Step [1/5], Loss: 0.2098, Accuracy: 98.02%, F1 Score: 0.91\n",
      "Epoch [8/1000], Step [1/5], Loss: 0.1968, Accuracy: 96.78%, F1 Score: 0.93\n",
      "Epoch [9/1000], Step [1/5], Loss: 0.1467, Accuracy: 98.39%, F1 Score: 0.95\n",
      "Epoch [10/1000], Step [1/5], Loss: 0.1424, Accuracy: 98.39%, F1 Score: 0.94\n",
      "Epoch [11/1000], Step [1/5], Loss: 0.1709, Accuracy: 99.26%, F1 Score: 0.94\n",
      "Epoch [12/1000], Step [1/5], Loss: 0.1357, Accuracy: 99.50%, F1 Score: 0.95\n",
      "Epoch [13/1000], Step [1/5], Loss: 0.1893, Accuracy: 99.13%, F1 Score: 0.94\n",
      "Epoch [14/1000], Step [1/5], Loss: 0.1421, Accuracy: 99.88%, F1 Score: 0.94\n",
      "Epoch [15/1000], Step [1/5], Loss: 0.1389, Accuracy: 99.38%, F1 Score: 0.95\n",
      "Epoch [16/1000], Step [1/5], Loss: 0.1929, Accuracy: 100.00%, F1 Score: 0.95\n",
      "Epoch [17/1000], Step [1/5], Loss: 0.1661, Accuracy: 100.00%, F1 Score: 0.96\n",
      "Epoch [18/1000], Step [1/5], Loss: 0.1709, Accuracy: 99.88%, F1 Score: 0.94\n",
      "Epoch [19/1000], Step [1/5], Loss: 0.1859, Accuracy: 100.00%, F1 Score: 0.95\n",
      "Epoch [20/1000], Step [1/5], Loss: 0.1770, Accuracy: 100.00%, F1 Score: 0.94\n",
      "Epoch [21/1000], Step [1/5], Loss: 0.1501, Accuracy: 100.00%, F1 Score: 0.94\n",
      "Epoch [22/1000], Step [1/5], Loss: 0.1566, Accuracy: 100.00%, F1 Score: 0.96\n",
      "\n",
      "----------------------------------------\n",
      "Early stopping at epoch 21\n",
      "Best epoch:  11\n",
      "Best loss:  0.13565894961357117  Best test F1 score:  0.9566481732781957  Best test accuracy:  0.958\n",
      "Training for model CNN2 kfolds:  5\n",
      "Epoch [1/1000], Step [1/5], Loss: 0.9667, Accuracy: 53.96%, F1 Score: 0.66\n",
      "Epoch [2/1000], Step [1/5], Loss: 0.5012, Accuracy: 81.68%, F1 Score: 0.81\n",
      "Epoch [3/1000], Step [1/5], Loss: 0.3740, Accuracy: 85.02%, F1 Score: 0.87\n",
      "Epoch [4/1000], Step [1/5], Loss: 0.3602, Accuracy: 91.09%, F1 Score: 0.89\n",
      "Epoch [5/1000], Step [1/5], Loss: 0.2439, Accuracy: 90.97%, F1 Score: 0.92\n",
      "Epoch [6/1000], Step [1/5], Loss: 0.2404, Accuracy: 93.69%, F1 Score: 0.93\n",
      "Epoch [7/1000], Step [1/5], Loss: 0.2076, Accuracy: 95.05%, F1 Score: 0.94\n",
      "Epoch [8/1000], Step [1/5], Loss: 0.2983, Accuracy: 95.79%, F1 Score: 0.91\n",
      "Epoch [9/1000], Step [1/5], Loss: 0.3327, Accuracy: 96.29%, F1 Score: 0.90\n",
      "Epoch [10/1000], Step [1/5], Loss: 0.2044, Accuracy: 98.64%, F1 Score: 0.93\n",
      "Epoch [11/1000], Step [1/5], Loss: 0.1926, Accuracy: 98.27%, F1 Score: 0.93\n",
      "Epoch [12/1000], Step [1/5], Loss: 0.1997, Accuracy: 98.89%, F1 Score: 0.93\n",
      "Epoch [13/1000], Step [1/5], Loss: 0.2172, Accuracy: 99.26%, F1 Score: 0.93\n",
      "Epoch [14/1000], Step [1/5], Loss: 0.2642, Accuracy: 99.26%, F1 Score: 0.93\n",
      "Epoch [15/1000], Step [1/5], Loss: 0.2139, Accuracy: 99.88%, F1 Score: 0.95\n",
      "Epoch [16/1000], Step [1/5], Loss: 0.2161, Accuracy: 99.63%, F1 Score: 0.95\n",
      "Epoch [17/1000], Step [1/5], Loss: 0.2624, Accuracy: 99.75%, F1 Score: 0.93\n",
      "Epoch [18/1000], Step [1/5], Loss: 0.2122, Accuracy: 99.75%, F1 Score: 0.93\n",
      "Epoch [19/1000], Step [1/5], Loss: 0.2239, Accuracy: 99.88%, F1 Score: 0.94\n",
      "Epoch [20/1000], Step [1/5], Loss: 0.2791, Accuracy: 100.00%, F1 Score: 0.93\n",
      "Epoch [21/1000], Step [1/5], Loss: 0.2701, Accuracy: 100.00%, F1 Score: 0.94\n",
      "\n",
      "----------------------------------------\n",
      "Early stopping at epoch 20\n",
      "Best epoch:  10\n",
      "Best loss:  0.19262972474098206  Best test F1 score:  0.9378135634200653  Best test accuracy:  0.938\n",
      "Training for model CNN2 kfolds:  6\n",
      "Epoch [1/1000], Step [1/5], Loss: 0.9233, Accuracy: 66.83%, F1 Score: 0.65\n",
      "Epoch [2/1000], Step [1/5], Loss: 0.5937, Accuracy: 81.68%, F1 Score: 0.78\n",
      "Epoch [3/1000], Step [1/5], Loss: 0.4403, Accuracy: 85.40%, F1 Score: 0.86\n",
      "Epoch [4/1000], Step [1/5], Loss: 0.3377, Accuracy: 91.09%, F1 Score: 0.91\n",
      "Epoch [5/1000], Step [1/5], Loss: 0.3251, Accuracy: 93.69%, F1 Score: 0.90\n",
      "Epoch [6/1000], Step [1/5], Loss: 0.3802, Accuracy: 95.30%, F1 Score: 0.90\n",
      "Epoch [7/1000], Step [1/5], Loss: 0.2822, Accuracy: 97.40%, F1 Score: 0.92\n",
      "Epoch [8/1000], Step [1/5], Loss: 0.2883, Accuracy: 97.77%, F1 Score: 0.92\n",
      "Epoch [9/1000], Step [1/5], Loss: 0.3117, Accuracy: 98.51%, F1 Score: 0.90\n",
      "Epoch [10/1000], Step [1/5], Loss: 0.2560, Accuracy: 99.13%, F1 Score: 0.93\n",
      "Epoch [11/1000], Step [1/5], Loss: 0.3165, Accuracy: 99.38%, F1 Score: 0.92\n",
      "Epoch [12/1000], Step [1/5], Loss: 0.2955, Accuracy: 99.63%, F1 Score: 0.90\n",
      "Epoch [13/1000], Step [1/5], Loss: 0.3201, Accuracy: 99.63%, F1 Score: 0.91\n",
      "Epoch [14/1000], Step [1/5], Loss: 0.3969, Accuracy: 99.50%, F1 Score: 0.91\n",
      "Epoch [15/1000], Step [1/5], Loss: 0.2811, Accuracy: 99.75%, F1 Score: 0.93\n",
      "Epoch [16/1000], Step [1/5], Loss: 0.3127, Accuracy: 99.88%, F1 Score: 0.94\n",
      "Epoch [17/1000], Step [1/5], Loss: 0.3210, Accuracy: 99.75%, F1 Score: 0.93\n",
      "Epoch [18/1000], Step [1/5], Loss: 0.3183, Accuracy: 99.88%, F1 Score: 0.92\n",
      "Epoch [19/1000], Step [1/5], Loss: 0.2829, Accuracy: 100.00%, F1 Score: 0.94\n",
      "Epoch [20/1000], Step [1/5], Loss: 0.3326, Accuracy: 100.00%, F1 Score: 0.92\n",
      "\n",
      "----------------------------------------\n",
      "Early stopping at epoch 19\n",
      "Best epoch:  9\n",
      "Best loss:  0.2559860050678253  Best test F1 score:  0.922298112064213  Best test accuracy:  0.92\n",
      "Training for model CNN2 kfolds:  7\n",
      "Epoch [1/1000], Step [1/5], Loss: 0.8180, Accuracy: 67.82%, F1 Score: 0.73\n",
      "Epoch [2/1000], Step [1/5], Loss: 0.4717, Accuracy: 84.41%, F1 Score: 0.78\n",
      "Epoch [3/1000], Step [1/5], Loss: 0.2927, Accuracy: 90.35%, F1 Score: 0.86\n",
      "Epoch [4/1000], Step [1/5], Loss: 0.2747, Accuracy: 89.11%, F1 Score: 0.88\n",
      "Epoch [5/1000], Step [1/5], Loss: 0.3045, Accuracy: 94.43%, F1 Score: 0.89\n",
      "Epoch [6/1000], Step [1/5], Loss: 0.2960, Accuracy: 96.78%, F1 Score: 0.91\n",
      "Epoch [7/1000], Step [1/5], Loss: 0.2598, Accuracy: 97.65%, F1 Score: 0.91\n",
      "Epoch [8/1000], Step [1/5], Loss: 0.2802, Accuracy: 97.28%, F1 Score: 0.90\n",
      "Epoch [9/1000], Step [1/5], Loss: 0.2908, Accuracy: 98.39%, F1 Score: 0.90\n",
      "Epoch [10/1000], Step [1/5], Loss: 0.3211, Accuracy: 99.26%, F1 Score: 0.91\n",
      "Epoch [11/1000], Step [1/5], Loss: 0.2995, Accuracy: 99.75%, F1 Score: 0.91\n",
      "Epoch [12/1000], Step [1/5], Loss: 0.3099, Accuracy: 99.50%, F1 Score: 0.92\n",
      "Epoch [13/1000], Step [1/5], Loss: 0.3247, Accuracy: 99.88%, F1 Score: 0.91\n",
      "Epoch [14/1000], Step [1/5], Loss: 0.2976, Accuracy: 100.00%, F1 Score: 0.92\n",
      "Epoch [15/1000], Step [1/5], Loss: 0.3089, Accuracy: 99.88%, F1 Score: 0.92\n",
      "Epoch [16/1000], Step [1/5], Loss: 0.3146, Accuracy: 99.75%, F1 Score: 0.93\n",
      "Epoch [17/1000], Step [1/5], Loss: 0.3494, Accuracy: 100.00%, F1 Score: 0.92\n",
      "\n",
      "----------------------------------------\n",
      "Early stopping at epoch 16\n",
      "Best epoch:  6\n",
      "Best loss:  0.2598355710506439  Best test F1 score:  0.919716738682256  Best test accuracy:  0.93\n",
      "Training for model CNN2 kfolds:  8\n",
      "Epoch [1/1000], Step [1/5], Loss: 1.1681, Accuracy: 52.10%, F1 Score: 0.59\n",
      "Epoch [2/1000], Step [1/5], Loss: 0.6812, Accuracy: 76.61%, F1 Score: 0.75\n",
      "Epoch [3/1000], Step [1/5], Loss: 0.4503, Accuracy: 82.67%, F1 Score: 0.83\n",
      "Epoch [4/1000], Step [1/5], Loss: 0.3885, Accuracy: 89.11%, F1 Score: 0.85\n",
      "Epoch [5/1000], Step [1/5], Loss: 0.3542, Accuracy: 90.97%, F1 Score: 0.86\n",
      "Epoch [6/1000], Step [1/5], Loss: 0.3036, Accuracy: 91.71%, F1 Score: 0.88\n",
      "Epoch [7/1000], Step [1/5], Loss: 0.2804, Accuracy: 94.80%, F1 Score: 0.88\n",
      "Epoch [8/1000], Step [1/5], Loss: 0.3394, Accuracy: 95.17%, F1 Score: 0.90\n",
      "Epoch [9/1000], Step [1/5], Loss: 0.3527, Accuracy: 96.04%, F1 Score: 0.88\n",
      "Epoch [10/1000], Step [1/5], Loss: 0.4134, Accuracy: 96.91%, F1 Score: 0.89\n",
      "Epoch [11/1000], Step [1/5], Loss: 0.3835, Accuracy: 97.28%, F1 Score: 0.88\n",
      "Epoch [12/1000], Step [1/5], Loss: 0.3630, Accuracy: 97.40%, F1 Score: 0.89\n",
      "Epoch [13/1000], Step [1/5], Loss: 0.3731, Accuracy: 98.27%, F1 Score: 0.91\n",
      "Epoch [14/1000], Step [1/5], Loss: 0.3915, Accuracy: 99.38%, F1 Score: 0.90\n",
      "Epoch [15/1000], Step [1/5], Loss: 0.3533, Accuracy: 99.38%, F1 Score: 0.91\n",
      "Epoch [16/1000], Step [1/5], Loss: 0.3909, Accuracy: 99.38%, F1 Score: 0.88\n",
      "Epoch [17/1000], Step [1/5], Loss: 0.4120, Accuracy: 100.00%, F1 Score: 0.90\n",
      "\n",
      "----------------------------------------\n",
      "Early stopping at epoch 16\n",
      "Best epoch:  6\n",
      "Best loss:  0.2803718149662018  Best test F1 score:  0.8989438479140996  Best test accuracy:  0.902\n",
      "Training for model CNN2 kfolds:  9\n",
      "Epoch [1/1000], Step [1/5], Loss: 0.7779, Accuracy: 65.97%, F1 Score: 0.71\n",
      "Epoch [2/1000], Step [1/5], Loss: 0.3359, Accuracy: 81.19%, F1 Score: 0.86\n",
      "Epoch [3/1000], Step [1/5], Loss: 0.2700, Accuracy: 87.75%, F1 Score: 0.91\n",
      "Epoch [4/1000], Step [1/5], Loss: 0.2361, Accuracy: 89.48%, F1 Score: 0.92\n",
      "Epoch [5/1000], Step [1/5], Loss: 0.1788, Accuracy: 94.55%, F1 Score: 0.92\n",
      "Epoch [6/1000], Step [1/5], Loss: 0.1343, Accuracy: 94.31%, F1 Score: 0.95\n",
      "Epoch [7/1000], Step [1/5], Loss: 0.1234, Accuracy: 96.41%, F1 Score: 0.96\n",
      "Epoch [8/1000], Step [1/5], Loss: 0.1052, Accuracy: 96.53%, F1 Score: 0.97\n",
      "Epoch [9/1000], Step [1/5], Loss: 0.1307, Accuracy: 97.77%, F1 Score: 0.95\n",
      "Epoch [10/1000], Step [1/5], Loss: 0.1267, Accuracy: 98.39%, F1 Score: 0.96\n",
      "Epoch [11/1000], Step [1/5], Loss: 0.1965, Accuracy: 98.89%, F1 Score: 0.93\n",
      "Epoch [12/1000], Step [1/5], Loss: 0.1364, Accuracy: 98.89%, F1 Score: 0.97\n",
      "Epoch [13/1000], Step [1/5], Loss: 0.1438, Accuracy: 99.26%, F1 Score: 0.96\n",
      "Epoch [14/1000], Step [1/5], Loss: 0.1392, Accuracy: 99.38%, F1 Score: 0.96\n",
      "Epoch [15/1000], Step [1/5], Loss: 0.1473, Accuracy: 99.63%, F1 Score: 0.95\n",
      "Epoch [16/1000], Step [1/5], Loss: 0.1535, Accuracy: 99.38%, F1 Score: 0.96\n",
      "Epoch [17/1000], Step [1/5], Loss: 0.1578, Accuracy: 99.88%, F1 Score: 0.96\n",
      "Epoch [18/1000], Step [1/5], Loss: 0.1382, Accuracy: 100.00%, F1 Score: 0.96\n",
      "\n",
      "----------------------------------------\n",
      "Early stopping at epoch 17\n",
      "Best epoch:  7\n",
      "Best loss:  0.10521160066127777  Best test F1 score:  0.9576426664626151  Best test accuracy:  0.958\n",
      "Training for model CNN2 kfolds:  10\n",
      "Epoch [1/1000], Step [1/5], Loss: 0.6221, Accuracy: 61.14%, F1 Score: 0.79\n",
      "Epoch [2/1000], Step [1/5], Loss: 0.3164, Accuracy: 83.66%, F1 Score: 0.87\n",
      "Epoch [3/1000], Step [1/5], Loss: 0.2419, Accuracy: 88.12%, F1 Score: 0.91\n",
      "Epoch [4/1000], Step [1/5], Loss: 0.2278, Accuracy: 92.70%, F1 Score: 0.91\n",
      "Epoch [5/1000], Step [1/5], Loss: 0.1896, Accuracy: 93.32%, F1 Score: 0.93\n",
      "Epoch [6/1000], Step [1/5], Loss: 0.1685, Accuracy: 95.42%, F1 Score: 0.92\n",
      "Epoch [7/1000], Step [1/5], Loss: 0.2079, Accuracy: 96.53%, F1 Score: 0.92\n",
      "Epoch [8/1000], Step [1/5], Loss: 0.2003, Accuracy: 98.39%, F1 Score: 0.93\n",
      "Epoch [9/1000], Step [1/5], Loss: 0.2064, Accuracy: 98.89%, F1 Score: 0.93\n",
      "Epoch [10/1000], Step [1/5], Loss: 0.1693, Accuracy: 99.26%, F1 Score: 0.93\n",
      "Epoch [11/1000], Step [1/5], Loss: 0.1638, Accuracy: 99.50%, F1 Score: 0.95\n",
      "Epoch [12/1000], Step [1/5], Loss: 0.1977, Accuracy: 99.63%, F1 Score: 0.92\n",
      "Epoch [13/1000], Step [1/5], Loss: 0.1844, Accuracy: 99.75%, F1 Score: 0.94\n",
      "Epoch [14/1000], Step [1/5], Loss: 0.1792, Accuracy: 99.63%, F1 Score: 0.94\n",
      "Epoch [15/1000], Step [1/5], Loss: 0.2026, Accuracy: 100.00%, F1 Score: 0.93\n",
      "Epoch [16/1000], Step [1/5], Loss: 0.1615, Accuracy: 99.88%, F1 Score: 0.95\n",
      "Epoch [17/1000], Step [1/5], Loss: 0.2018, Accuracy: 100.00%, F1 Score: 0.95\n",
      "Epoch [18/1000], Step [1/5], Loss: 0.1577, Accuracy: 100.00%, F1 Score: 0.95\n",
      "Epoch [19/1000], Step [1/5], Loss: 0.2374, Accuracy: 100.00%, F1 Score: 0.95\n",
      "Epoch [20/1000], Step [1/5], Loss: 0.2021, Accuracy: 100.00%, F1 Score: 0.96\n",
      "Epoch [21/1000], Step [1/5], Loss: 0.2014, Accuracy: 100.00%, F1 Score: 0.95\n",
      "Epoch [22/1000], Step [1/5], Loss: 0.1893, Accuracy: 100.00%, F1 Score: 0.95\n",
      "Epoch [23/1000], Step [1/5], Loss: 0.1983, Accuracy: 100.00%, F1 Score: 0.95\n",
      "Epoch [24/1000], Step [1/5], Loss: 0.2229, Accuracy: 100.00%, F1 Score: 0.95\n",
      "Epoch [25/1000], Step [1/5], Loss: 0.2375, Accuracy: 100.00%, F1 Score: 0.94\n",
      "Epoch [26/1000], Step [1/5], Loss: 0.1950, Accuracy: 100.00%, F1 Score: 0.96\n",
      "Epoch [27/1000], Step [1/5], Loss: 0.2060, Accuracy: 100.00%, F1 Score: 0.95\n",
      "Epoch [28/1000], Step [1/5], Loss: 0.2040, Accuracy: 100.00%, F1 Score: 0.95\n",
      "\n",
      "----------------------------------------\n",
      "Early stopping at epoch 27\n",
      "Best epoch:  17\n",
      "Best loss:  0.1577390879392624  Best test F1 score:  0.9495763008614049  Best test accuracy:  0.952\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if (trains_kfolds):\n",
    "\n",
    "    for i in range(1, 11):\n",
    "        model = CNN2().to(device)\n",
    "        model.to(device)\n",
    "\n",
    "        print(\"Training for model %s\"%(model.name), \"kfolds: \", i)\n",
    "        data_loader = torch.load('kfolds/data_loader_kfold%s.pt'%(i))\n",
    "        valid_loader = torch.load('kfolds/valid_loader_kfold%s.pt'%(i))\n",
    "\n",
    "        # Move the data loaders to the desired device\n",
    "        data_loader.dataset.tensors = tuple(tensor.to(device) for tensor in data_loader.dataset.tensors)\n",
    "        valid_loader.dataset.tensors = tuple(tensor.to(device) for tensor in valid_loader.dataset.tensors)\n",
    "        \n",
    "        train_and_save_model(model, data_loader, valid_loader, device, 'trained_k_folds/CNN_kfold_%s_%s'%(model.name, i))\n",
    "\n",
    "        # clearing cache\n",
    "        del model, data_loader, valid_loader\n",
    "        torch.cuda.empty_cache()\n",
    "else:\n",
    "    model2 = CNN2().to(device)\n",
    "    train_and_save_model(model2, data_loader, valid_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Step [1/4], Loss: 1.2100, Accuracy: 36.68%, F1 Score: 0.33\n",
      "Epoch [2/1000], Step [1/4], Loss: 0.8203, Accuracy: 67.99%, F1 Score: 0.65\n",
      "Epoch [3/1000], Step [1/4], Loss: 0.6293, Accuracy: 76.05%, F1 Score: 0.75\n",
      "Epoch [4/1000], Step [1/4], Loss: 0.5338, Accuracy: 81.89%, F1 Score: 0.80\n",
      "Epoch [5/1000], Step [1/4], Loss: 0.4419, Accuracy: 88.55%, F1 Score: 0.84\n",
      "Epoch [6/1000], Step [1/4], Loss: 0.4042, Accuracy: 87.97%, F1 Score: 0.85\n",
      "Epoch [7/1000], Step [1/4], Loss: 0.3546, Accuracy: 87.73%, F1 Score: 0.86\n",
      "Epoch [8/1000], Step [1/4], Loss: 0.3080, Accuracy: 90.65%, F1 Score: 0.89\n",
      "Epoch [9/1000], Step [1/4], Loss: 0.3256, Accuracy: 91.00%, F1 Score: 0.89\n",
      "Epoch [10/1000], Step [1/4], Loss: 0.2853, Accuracy: 93.57%, F1 Score: 0.90\n",
      "Epoch [11/1000], Step [1/4], Loss: 0.2892, Accuracy: 94.51%, F1 Score: 0.90\n",
      "Epoch [12/1000], Step [1/4], Loss: 0.3188, Accuracy: 95.91%, F1 Score: 0.90\n",
      "Epoch [13/1000], Step [1/4], Loss: 0.2850, Accuracy: 94.04%, F1 Score: 0.92\n",
      "Epoch [14/1000], Step [1/4], Loss: 0.3229, Accuracy: 94.63%, F1 Score: 0.91\n",
      "Epoch [15/1000], Step [1/4], Loss: 0.3477, Accuracy: 96.85%, F1 Score: 0.91\n",
      "Epoch [16/1000], Step [1/4], Loss: 0.3400, Accuracy: 96.38%, F1 Score: 0.91\n",
      "Epoch [17/1000], Step [1/4], Loss: 0.3353, Accuracy: 97.66%, F1 Score: 0.92\n",
      "Epoch [18/1000], Step [1/4], Loss: 0.3606, Accuracy: 97.78%, F1 Score: 0.91\n",
      "Epoch [19/1000], Step [1/4], Loss: 0.3771, Accuracy: 98.48%, F1 Score: 0.92\n",
      "Epoch [20/1000], Step [1/4], Loss: 0.3781, Accuracy: 98.01%, F1 Score: 0.92\n",
      "Epoch [21/1000], Step [1/4], Loss: 0.3952, Accuracy: 98.25%, F1 Score: 0.91\n",
      "Epoch [22/1000], Step [1/4], Loss: 0.4145, Accuracy: 97.55%, F1 Score: 0.91\n",
      "Epoch [23/1000], Step [1/4], Loss: 0.3722, Accuracy: 98.36%, F1 Score: 0.92\n",
      "\n",
      "----------------------------------------\n",
      "Early stopping at epoch 22\n",
      "Best epoch:  12\n",
      "Best loss:  0.2850208878517151  Best test F1 score:  0.9237520396937595  Best test accuracy:  0.924\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model3 = CNN3().to(device)\n",
    "if (trains_kfolds):\n",
    "    model = model3\n",
    "    for i in range(1, 11):\n",
    "        print(\"Training for model %s\"%(model.name), \"kfolds: \", i)\n",
    "        data_loader = torch.load('kfolds/data_loader_kfold%s.pt'%(i))\n",
    "        valid_loader = torch.load('kfolds/valid_loader_kfold%s.pt'%(i))\n",
    "        train_and_save_model(model, data_loader, valid_loader, device, 'trained_k_folds/CNN_kfold_%s_%s'%(model.name, i))\n",
    "else:\n",
    "    train_and_save_model(model3, data_loader, valid_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, valid_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "        for images, labels in valid_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "        print('Test Accuracy of the model (validation): {:.2f} %'\n",
    "        .format((correct / total) * 100))\n",
    "        print('F1 Score of the model (validation): {:.2f} %'\n",
    "        .format((f1_score(all_labels, all_predictions, average='macro')) * 100))\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "        print('Test Accuracy of the model (testing): {:.2f} %'\n",
    "        .format((correct / total) * 100))\n",
    "        print('F1 Score of the model (testing): {:.2f} %'\n",
    "        .format((f1_score(all_labels, all_predictions, average='macro')) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model:  CNN2 \n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'valid_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m [model2]:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mModel: \u001b[39m\u001b[38;5;124m'\u001b[39m, model\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     evaluate_model(model, \u001b[43mvalid_loader\u001b[49m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m     test_model(model, test_loader)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'valid_loader' is not defined"
     ]
    }
   ],
   "source": [
    "model2 = CNN2().to(device)\n",
    "#load the weights of the model\n",
    "model2.load_state_dict(torch.load('trained_k_folds/CNN_kfold_CNN2_10.pth', map_location=device))\n",
    "for model in [model2]:\n",
    "    print('\\nModel: ', model.name, '\\n')\n",
    "\n",
    "    evaluate_model(model, valid_loader)\n",
    "    print('\\n')\n",
    "    test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to test an individual image from an external source\n",
    "def test_individual_image(model, image_name, category, read_custom_path = ''):\n",
    "    if (read_custom_path != ''):\n",
    "        img = cv2.imread(read_custom_path, 0)\n",
    "        image_name = read_custom_path\n",
    "        #save the image\n",
    "    else:\n",
    "        img = cv2.imread(\"../concat_data/%s/%s\" % (category, image_name), 0)\n",
    "    \n",
    "    #resize to 48x48 pixels\n",
    "    img = cv2.resize(img, (48, 48))\n",
    "\n",
    "\n",
    "\n",
    "    #if image 3 channel convert to 1 channel\n",
    "    if len(img.shape) > 2:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    cv2.imwrite(\"image_mod.jpg\", img)\n",
    "    \n",
    "    # Convert image to tensor and add batch and channel dimensions\n",
    "    img_tensor = torch.tensor(img, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    # Get label tensor\n",
    "    labels = {'focused': 0, 'happy': 1, 'neutral': 2, 'surprised': 3}\n",
    "    reverse_labels = {0: 'focused', 1: 'happy', 2: 'neutral', 3: 'surprised'}\n",
    "    label_tensor = torch.tensor(labels[category], dtype=torch.long)\n",
    "\n",
    "    # Forward pass for the single image\n",
    "    img_tensor = img_tensor.to(device)\n",
    "    output = model(img_tensor)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "\n",
    "    # Print results\n",
    "    print(\"Predicted:\", predicted.item(), \"(\", reverse_labels[predicted.item()], \")\")\n",
    "    print(\"Actual:\", label_tensor.item(), \"(\", reverse_labels[label_tensor.item()], \")\")\n",
    "    print(\"Image:\", image_name)\n",
    "    print(\"Category:\", category)\n",
    "    print(\"///////\")\n",
    "    \n",
    "    return predicted.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 1 ( happy )\n",
      "Actual: 1 ( happy )\n",
      "Image: ../unseen-test-imgs/test_smile.PNG\n",
      "Category: happy\n",
      "///////\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_individual_image(model2, \"86_MMA-FACIAL-EXPRESSION-mahmoud.jpg\", \"happy\", read_custom_path=r\"../unseen-test-imgs/test_smile.PNG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0 ( focused )\n",
      "Actual: 2 ( neutral )\n",
      "Image: ../unseen-test-imgs/test_neutral.PNG\n",
      "Category: neutral\n",
      "///////\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_individual_image(model2, \"86_MMA-FACIAL-EXPRESSION-mahmoud.jpg\", \"neutral\", read_custom_path=r\"../unseen-test-imgs/test_neutral.PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0 ( focused )\n",
      "Actual: 0 ( focused )\n",
      "Image: ../unseen-test-imgs/test_focused.PNG\n",
      "Category: focused\n",
      "///////\n",
      "Predicted: 3 ( surprised )\n",
      "Actual: 0 ( focused )\n",
      "Image: ../unseen-test-imgs/test_focused_2.PNG\n",
      "Category: focused\n",
      "///////\n",
      "Predicted: 0 ( focused )\n",
      "Actual: 0 ( focused )\n",
      "Image: ../unseen-test-imgs/test_focused_3.PNG\n",
      "Category: focused\n",
      "///////\n",
      "Predicted: 1 ( happy )\n",
      "Actual: 0 ( focused )\n",
      "Image: ../unseen-test-imgs/test_focused_4.PNG\n",
      "Category: focused\n",
      "///////\n",
      "Predicted: 0 ( focused )\n",
      "Actual: 0 ( focused )\n",
      "Image: ../unseen-test-imgs/test_focused_5.PNG\n",
      "Category: focused\n",
      "///////\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_individual_image(model2, \"86_MMA-FACIAL-EXPRESSION-mahmoud.jpg\", \"focused\", read_custom_path=r\"../unseen-test-imgs/test_focused.PNG\")\n",
    "test_individual_image(model2, \"86_MMA-FACIAL-EXPRESSION-mahmoud.jpg\", \"focused\", read_custom_path=r\"../unseen-test-imgs/test_focused_2.PNG\")\n",
    "test_individual_image(model2, \"86_MMA-FACIAL-EXPRESSION-mahmoud.jpg\", \"focused\", read_custom_path=r\"../unseen-test-imgs/test_focused_3.PNG\")\n",
    "test_individual_image(model2, \"86_MMA-FACIAL-EXPRESSION-mahmoud.jpg\", \"focused\", read_custom_path=r\"../unseen-test-imgs/test_focused_4.PNG\")\n",
    "test_individual_image(model2, \"86_MMA-FACIAL-EXPRESSION-mahmoud.jpg\", \"focused\", read_custom_path=r\"../unseen-test-imgs/test_focused_5.PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 3 ( surprised )\n",
      "Actual: 3 ( surprised )\n",
      "Image: ../unseen-test-imgs/test_surprised.PNG\n",
      "Category: surprised\n",
      "///////\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_individual_image(model2, \"86_MMA-FACIAL-EXPRESSION-mahmoud.jpg\", \"surprised\", read_custom_path=r\"../unseen-test-imgs/test_surprised.PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@1142.759] global loadsave.cpp:248 findDecoder imread_('../concat_data/focused/86_MMA-FACIAL-EXPRESSION-mahmoud.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) /io/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[123], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_individual_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m86_MMA-FACIAL-EXPRESSION-mahmoud.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfocused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[118], line 11\u001b[0m, in \u001b[0;36mtest_individual_image\u001b[0;34m(model, image_name, category, read_custom_path)\u001b[0m\n\u001b[1;32m      8\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../concat_data/\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (category, image_name), \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#resize to 48x48 pixels\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m48\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m48\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#if image 3 channel convert to 1 channel\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(img\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.9.0) /io/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
     ]
    }
   ],
   "source": [
    "test_individual_image(model1, \"86_MMA-FACIAL-EXPRESSION-mahmoud.jpg\", \"focused\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
